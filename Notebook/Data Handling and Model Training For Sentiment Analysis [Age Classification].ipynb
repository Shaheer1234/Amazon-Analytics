{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "import codecs\n",
    "mypath =\"/Anaconda/blogs\"\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from time import time\n",
    "import sys\n",
    "import scipy.sparse as sp\n",
    "import pylab as pl\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_mlcomp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def benchmark(clf_class, params, name):\n",
    "    print(\"parameters:\", params)\n",
    "    t0 = time()\n",
    "    clf = clf_class(**params).fit(Xtrain, y_train)\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"Percentage of non zeros coef: %f\"\n",
    "              % (np.mean(clf.coef_ != 0) * 100))\n",
    "    print(\"Predicting the outcomes of the testing set\")\n",
    "    t0 = time()\n",
    "    pred = clf.predict(Xtest)\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Classification report on test set for classifier:\")\n",
    "    print(clf)\n",
    "    print()\n",
    "    print(classification_report(y_test, pred))\n",
    "    \n",
    "    with open(name+'.pkl', 'wb') as fid:\n",
    "        cPickle.dump(clf, fid) \n",
    "    \n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Show confusion matrix\n",
    "    pl.matshow(cm)\n",
    "    pl.title('Confusion matrix of the %s classifier' % name)\n",
    "    pl.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_documentIndex(listOfDocuments):\n",
    "    dict_of_words = {}\n",
    "    doc_corpus = []\n",
    "    for doc in listOfDocuments:           \n",
    "        file = open(mypath+\"/\"+doc)\n",
    "        str = file.read()\n",
    "        doc_corpus.append(str)\n",
    "\n",
    "        \n",
    "       \n",
    "    return doc_corpus   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = make_documentIndex(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19320"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def HandleDataAndLabels(coprus,onlyfiles):\n",
    "    Y = []\n",
    "    X = []\n",
    "    numFiles = len(onlyfiles)\n",
    "    for f in range(0,numFiles):\n",
    "        age = onlyfiles[f].split('.')[2]\n",
    "        ag = 0\n",
    "        if int(age) <= 17:\n",
    "            ag= 1\n",
    "        elif int(age) >17 and int(age)< 33:\n",
    "            ag= 2\n",
    "        elif int(age) >=33:\n",
    "            ag= 3\n",
    "     \n",
    "        soup = BeautifulSoup(corpus[f],\"lxml\")\n",
    "        result= soup.findAll('post')\n",
    "        for a in result:\n",
    "            X.append(a.get_text())\n",
    "            Y.append(ag)\n",
    "            \n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X,Y = HandleDataAndLabels(corpus,onlyfiles)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data X,Y 681253 681253\n",
      "Xtrain,Ytrain  476877 476877\n",
      "XTest, YTest  204376 204376\n"
     ]
    }
   ],
   "source": [
    "print \"Original Data X,Y\",len(X),len(Y)\n",
    "print \"Xtrain,Ytrain \",len(X_train),len(y_train)\n",
    "print \"XTest, YTest \",len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 116.214000s\n",
      "n_samples: 476877, n_features: 586663\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(encoding='utf-8')\n",
    "Xtrain = vectorizer.fit_transform(X_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % Xtrain.shape)\n",
    "assert sp.issparse(Xtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TFIDF_Vectorizer.pkl', 'wb') as fid:\n",
    "    cPickle.dump(vectorizer, fid)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 46.528000s\n",
      "n_samples: 204376, n_features: 586663\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time()\n",
    "Xtest = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % Xtest.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  6.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 395.579000s\n",
      "Predicting the outcomes of the testing set\n",
      "done in 6.061000s\n",
      "Classification report on test set for classifier:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=32, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
      "            oob_score=False, random_state=None, verbose=True,\n",
      "            warm_start=False)\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.92      0.23      0.36     70783\n",
      "          2       0.51      0.99      0.67     96334\n",
      "          3       0.97      0.01      0.01     37259\n",
      "\n",
      "avg / total       0.74      0.54      0.44    204376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "clf = RandomForestClassifier(n_estimators=100,max_depth=32,n_jobs=4,verbose=True)\n",
    "clf.fit(Xtrain, y_train)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "if hasattr(clf, 'coef_'):\n",
    "    print(\"Percentage of non zeros coef: %f\"\n",
    "          % (np.mean(clf.coef_ != 0) * 100))\n",
    "print(\"Predicting the outcomes of the testing set\")\n",
    "t0 = time()\n",
    "pred = clf.predict(Xtest)\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "print(\"Classification report on test set for classifier:\")\n",
    "print(clf)\n",
    "print()\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\\nimportances = clf.feature_importances_\\nstd = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\\nindices = np.argsort(importances)[::-1]\\n\\n# Print the feature ranking\\nprint(\"Feature ranking:\")\\n\\nfor f in range(Xtrain.shape[1]):\\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\\n\\n# Plot the feature importances of the forest\\nplt.figure()\\nplt.title(\"Feature importances\")\\nplt.bar(range(Xtrain.shape[1]), importances[indices],\\n       color=\"r\", yerr=std[indices], align=\"center\")\\nplt.xticks(range(X.shape[1]), indices)\\nplt.xlim([-1, X.shape[1]])\\nplt.show()\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(Xtrain.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(Xtrain.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('RF_classifier2.pkl', 'wb') as fid:\n",
    "    cPickle.dump(clf, fid)    \n",
    "\n",
    "# load it again\n",
    "#with open('my_dumped_classifier.pkl', 'rb') as fid:\n",
    " #   gnb_loaded = cPickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testbenching a MultinomialNB classifier...\n",
      "('parameters:', {'alpha': 0.01})\n",
      "done in 0.900000s\n",
      "Percentage of non zeros coef: 100.000000\n",
      "Predicting the outcomes of the testing set\n",
      "done in 0.338000s\n",
      "Classification report on test set for classifier:\n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.68      0.73     70564\n",
      "          2       0.64      0.85      0.73     96614\n",
      "          3       0.64      0.30      0.40     37198\n",
      "\n",
      "avg / total       0.70      0.69      0.67    204376\n",
      "\n",
      "Confusion matrix:\n",
      "[[47665 21730  1169]\n",
      " [ 9799 81674  5141]\n",
      " [ 1931 24221 11046]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testbenching a MultinomialNB classifier...\")\n",
    "parameters = {'alpha': 0.01}\n",
    "\n",
    "benchmark(MultinomialNB, parameters, 'MultiNB')\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testbenching a linear classifier...\n",
      "('parameters:', {'penalty': 'l2', 'loss': 'hinge', 'alpha': 1e-05, 'fit_intercept': True, 'n_iter': 50})\n",
      "done in 51.508000s\n",
      "Percentage of non zeros coef: 71.303162\n",
      "Predicting the outcomes of the testing set\n",
      "done in 0.275000s\n",
      "Classification report on test set for classifier:\n",
      "SGDClassifier(alpha=1e-05, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74     70805\n",
      "          2       0.63      0.86      0.73     96773\n",
      "          3       0.76      0.15      0.26     36798\n",
      "\n",
      "avg / total       0.70      0.68      0.65    204376\n",
      "\n",
      "Confusion matrix:\n",
      "[[50447 19957   401]\n",
      " [11953 83416  1404]\n",
      " [ 2929 28166  5703]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testbenching a linear classifier...\")\n",
    "parameters = {\n",
    "    'loss': 'hinge',\n",
    "    'penalty': 'l2',\n",
    "    'n_iter': 50,\n",
    "    'alpha': 0.00001,\n",
    "    'fit_intercept': True,\n",
    "}\n",
    "\n",
    "benchmark(SGDClassifier, parameters, 'SGD')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testbenching a logistic Regression...\n",
      "('parameters:', {'loss': 'log', 'verbose': True, 'fit_intercept': True, 'n_iter': 250, 'penalty': 'l2', 'alpha': 1e-06})\n",
      "-- Epoch 1\n",
      "Norm: 335.66, NNZs: 589993, Bias: -0.737125, T: 476877, Avg. loss: 0.611524\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 297.43, NNZs: 589993, Bias: -0.877073, T: 953754, Avg. loss: 0.485343\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 286.99, NNZs: 589993, Bias: -0.780909, T: 1430631, Avg. loss: 0.437168\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 282.28, NNZs: 589993, Bias: -0.805562, T: 1907508, Avg. loss: 0.411354\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 279.50, NNZs: 589993, Bias: -0.838697, T: 2384385, Avg. loss: 0.395094\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 277.59, NNZs: 589993, Bias: -0.861567, T: 2861262, Avg. loss: 0.383832\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 276.54, NNZs: 589993, Bias: -0.794518, T: 3338139, Avg. loss: 0.375537\n",
      "Total training time: 2.94 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 275.61, NNZs: 589993, Bias: -0.847505, T: 3815016, Avg. loss: 0.369164\n",
      "Total training time: 3.37 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 275.01, NNZs: 589993, Bias: -0.909516, T: 4291893, Avg. loss: 0.364094\n",
      "Total training time: 3.81 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 274.40, NNZs: 589993, Bias: -0.830608, T: 4768770, Avg. loss: 0.359958\n",
      "Total training time: 4.24 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 273.93, NNZs: 589993, Bias: -0.804573, T: 5245647, Avg. loss: 0.356521\n",
      "Total training time: 4.66 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 273.58, NNZs: 589993, Bias: -0.854293, T: 5722524, Avg. loss: 0.353612\n",
      "Total training time: 5.08 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 273.28, NNZs: 589993, Bias: -0.807371, T: 6199401, Avg. loss: 0.351119\n",
      "Total training time: 5.50 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 273.00, NNZs: 589993, Bias: -0.847245, T: 6676278, Avg. loss: 0.348956\n",
      "Total training time: 5.91 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 272.79, NNZs: 589993, Bias: -0.808436, T: 7153155, Avg. loss: 0.347061\n",
      "Total training time: 6.32 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 272.57, NNZs: 589993, Bias: -0.819901, T: 7630032, Avg. loss: 0.345383\n",
      "Total training time: 6.75 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 272.36, NNZs: 589993, Bias: -0.821928, T: 8106909, Avg. loss: 0.343887\n",
      "Total training time: 7.21 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 272.22, NNZs: 589993, Bias: -0.852776, T: 8583786, Avg. loss: 0.342545\n",
      "Total training time: 7.62 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 272.10, NNZs: 589993, Bias: -0.822375, T: 9060663, Avg. loss: 0.341334\n",
      "Total training time: 8.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 271.98, NNZs: 589993, Bias: -0.798753, T: 9537540, Avg. loss: 0.340231\n",
      "Total training time: 8.59 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 271.85, NNZs: 589993, Bias: -0.806475, T: 10014417, Avg. loss: 0.339227\n",
      "Total training time: 9.07 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 271.74, NNZs: 589993, Bias: -0.835848, T: 10491294, Avg. loss: 0.338308\n",
      "Total training time: 9.54 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 271.63, NNZs: 589993, Bias: -0.832348, T: 10968171, Avg. loss: 0.337465\n",
      "Total training time: 10.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 271.52, NNZs: 589993, Bias: -0.839184, T: 11445048, Avg. loss: 0.336686\n",
      "Total training time: 10.49 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 271.45, NNZs: 589993, Bias: -0.809243, T: 11921925, Avg. loss: 0.335964\n",
      "Total training time: 10.97 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 271.39, NNZs: 589993, Bias: -0.813763, T: 12398802, Avg. loss: 0.335294\n",
      "Total training time: 11.41 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 271.32, NNZs: 589993, Bias: -0.811127, T: 12875679, Avg. loss: 0.334669\n",
      "Total training time: 11.82 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 271.23, NNZs: 589993, Bias: -0.823538, T: 13352556, Avg. loss: 0.334087\n",
      "Total training time: 12.25 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 271.18, NNZs: 589993, Bias: -0.808284, T: 13829433, Avg. loss: 0.333542\n",
      "Total training time: 12.66 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 271.12, NNZs: 589993, Bias: -0.797801, T: 14306310, Avg. loss: 0.333030\n",
      "Total training time: 13.06 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 271.07, NNZs: 589993, Bias: -0.835900, T: 14783187, Avg. loss: 0.332547\n",
      "Total training time: 13.47 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 270.99, NNZs: 589993, Bias: -0.832868, T: 15260064, Avg. loss: 0.332094\n",
      "Total training time: 13.88 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 270.95, NNZs: 589993, Bias: -0.861263, T: 15736941, Avg. loss: 0.331665\n",
      "Total training time: 14.30 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 270.90, NNZs: 589993, Bias: -0.832812, T: 16213818, Avg. loss: 0.331260\n",
      "Total training time: 14.76 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 270.87, NNZs: 589993, Bias: -0.823338, T: 16690695, Avg. loss: 0.330878\n",
      "Total training time: 15.18 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 270.82, NNZs: 589993, Bias: -0.818617, T: 17167572, Avg. loss: 0.330515\n",
      "Total training time: 15.61 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 270.77, NNZs: 589993, Bias: -0.820212, T: 17644449, Avg. loss: 0.330170\n",
      "Total training time: 16.09 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 270.73, NNZs: 589993, Bias: -0.833962, T: 18121326, Avg. loss: 0.329841\n",
      "Total training time: 16.58 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 270.70, NNZs: 589993, Bias: -0.804612, T: 18598203, Avg. loss: 0.329528\n",
      "Total training time: 17.07 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 270.66, NNZs: 589993, Bias: -0.838505, T: 19075080, Avg. loss: 0.329230\n",
      "Total training time: 17.53 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 270.63, NNZs: 589993, Bias: -0.808449, T: 19551957, Avg. loss: 0.328944\n",
      "Total training time: 17.94 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 270.62, NNZs: 589993, Bias: -0.821296, T: 20028834, Avg. loss: 0.328672\n",
      "Total training time: 18.35 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 270.57, NNZs: 589993, Bias: -0.841548, T: 20505711, Avg. loss: 0.328412\n",
      "Total training time: 18.76 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 270.56, NNZs: 589993, Bias: -0.837757, T: 20982588, Avg. loss: 0.328162\n",
      "Total training time: 19.17 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 270.53, NNZs: 589993, Bias: -0.811473, T: 21459465, Avg. loss: 0.327923\n",
      "Total training time: 19.59 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 270.50, NNZs: 589993, Bias: -0.824771, T: 21936342, Avg. loss: 0.327693\n",
      "Total training time: 20.08 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 270.47, NNZs: 589993, Bias: -0.837635, T: 22413219, Avg. loss: 0.327473\n",
      "Total training time: 20.55 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 270.45, NNZs: 589993, Bias: -0.818703, T: 22890096, Avg. loss: 0.327261\n",
      "Total training time: 21.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 270.43, NNZs: 589993, Bias: -0.829552, T: 23366973, Avg. loss: 0.327057\n",
      "Total training time: 21.41 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 270.41, NNZs: 589993, Bias: -0.804679, T: 23843850, Avg. loss: 0.326860\n",
      "Total training time: 21.81 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 270.38, NNZs: 589993, Bias: -0.827707, T: 24320727, Avg. loss: 0.326671\n",
      "Total training time: 22.23 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 270.37, NNZs: 589993, Bias: -0.820393, T: 24797604, Avg. loss: 0.326489\n",
      "Total training time: 22.68 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 270.35, NNZs: 589993, Bias: -0.811378, T: 25274481, Avg. loss: 0.326312\n",
      "Total training time: 23.14 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 270.32, NNZs: 589993, Bias: -0.824064, T: 25751358, Avg. loss: 0.326143\n",
      "Total training time: 23.59 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 270.29, NNZs: 589993, Bias: -0.825193, T: 26228235, Avg. loss: 0.325978\n",
      "Total training time: 24.00 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 270.28, NNZs: 589993, Bias: -0.824786, T: 26705112, Avg. loss: 0.325819\n",
      "Total training time: 24.42 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 270.27, NNZs: 589993, Bias: -0.825039, T: 27181989, Avg. loss: 0.325666\n",
      "Total training time: 24.87 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 270.26, NNZs: 589993, Bias: -0.833226, T: 27658866, Avg. loss: 0.325517\n",
      "Total training time: 25.34 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 270.25, NNZs: 589993, Bias: -0.817905, T: 28135743, Avg. loss: 0.325373\n",
      "Total training time: 25.75 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 270.22, NNZs: 589993, Bias: -0.825362, T: 28612620, Avg. loss: 0.325233\n",
      "Total training time: 26.16 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 270.22, NNZs: 589993, Bias: -0.824855, T: 29089497, Avg. loss: 0.325098\n",
      "Total training time: 26.61 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 270.20, NNZs: 589993, Bias: -0.826166, T: 29566374, Avg. loss: 0.324966\n",
      "Total training time: 27.04 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 270.19, NNZs: 589993, Bias: -0.817756, T: 30043251, Avg. loss: 0.324839\n",
      "Total training time: 27.50 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 270.16, NNZs: 589993, Bias: -0.827919, T: 30520128, Avg. loss: 0.324716\n",
      "Total training time: 27.91 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 270.16, NNZs: 589993, Bias: -0.823320, T: 30997005, Avg. loss: 0.324595\n",
      "Total training time: 28.38 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 270.15, NNZs: 589993, Bias: -0.817078, T: 31473882, Avg. loss: 0.324479\n",
      "Total training time: 28.84 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 270.13, NNZs: 589993, Bias: -0.835022, T: 31950759, Avg. loss: 0.324365\n",
      "Total training time: 29.24 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 270.12, NNZs: 589993, Bias: -0.819925, T: 32427636, Avg. loss: 0.324255\n",
      "Total training time: 29.65 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 270.11, NNZs: 589993, Bias: -0.832011, T: 32904513, Avg. loss: 0.324147\n",
      "Total training time: 30.07 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 270.10, NNZs: 589993, Bias: -0.805773, T: 33381390, Avg. loss: 0.324043\n",
      "Total training time: 30.48 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 270.08, NNZs: 589993, Bias: -0.828094, T: 33858267, Avg. loss: 0.323941\n",
      "Total training time: 30.89 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 270.08, NNZs: 589993, Bias: -0.815598, T: 34335144, Avg. loss: 0.323842\n",
      "Total training time: 31.30 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 270.07, NNZs: 589993, Bias: -0.826483, T: 34812021, Avg. loss: 0.323745\n",
      "Total training time: 31.71 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 270.05, NNZs: 589993, Bias: -0.842876, T: 35288898, Avg. loss: 0.323651\n",
      "Total training time: 32.12 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 270.05, NNZs: 589993, Bias: -0.813730, T: 35765775, Avg. loss: 0.323559\n",
      "Total training time: 32.54 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 270.03, NNZs: 589993, Bias: -0.820780, T: 36242652, Avg. loss: 0.323469\n",
      "Total training time: 32.95 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 270.02, NNZs: 589993, Bias: -0.817261, T: 36719529, Avg. loss: 0.323382\n",
      "Total training time: 33.35 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 270.02, NNZs: 589993, Bias: -0.825259, T: 37196406, Avg. loss: 0.323296\n",
      "Total training time: 33.76 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 270.01, NNZs: 589993, Bias: -0.829893, T: 37673283, Avg. loss: 0.323213\n",
      "Total training time: 34.16 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 270.00, NNZs: 589993, Bias: -0.825660, T: 38150160, Avg. loss: 0.323132\n",
      "Total training time: 34.57 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 269.99, NNZs: 589993, Bias: -0.833122, T: 38627037, Avg. loss: 0.323052\n",
      "Total training time: 34.97 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 269.98, NNZs: 589993, Bias: -0.829282, T: 39103914, Avg. loss: 0.322975\n",
      "Total training time: 35.38 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 269.97, NNZs: 589993, Bias: -0.833025, T: 39580791, Avg. loss: 0.322899\n",
      "Total training time: 35.79 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 269.97, NNZs: 589993, Bias: -0.810170, T: 40057668, Avg. loss: 0.322824\n",
      "Total training time: 36.19 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 269.96, NNZs: 589993, Bias: -0.827062, T: 40534545, Avg. loss: 0.322752\n",
      "Total training time: 36.60 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 269.95, NNZs: 589993, Bias: -0.828918, T: 41011422, Avg. loss: 0.322680\n",
      "Total training time: 37.01 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 269.94, NNZs: 589993, Bias: -0.830315, T: 41488299, Avg. loss: 0.322611\n",
      "Total training time: 37.41 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 269.93, NNZs: 589993, Bias: -0.827675, T: 41965176, Avg. loss: 0.322543\n",
      "Total training time: 37.84 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 269.92, NNZs: 589993, Bias: -0.822530, T: 42442053, Avg. loss: 0.322476\n",
      "Total training time: 38.25 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 269.92, NNZs: 589993, Bias: -0.814518, T: 42918930, Avg. loss: 0.322411\n",
      "Total training time: 38.66 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 269.91, NNZs: 589993, Bias: -0.819951, T: 43395807, Avg. loss: 0.322347\n",
      "Total training time: 39.07 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 269.90, NNZs: 589993, Bias: -0.827108, T: 43872684, Avg. loss: 0.322284\n",
      "Total training time: 39.49 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 269.90, NNZs: 589993, Bias: -0.828682, T: 44349561, Avg. loss: 0.322223\n",
      "Total training time: 39.90 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 269.90, NNZs: 589993, Bias: -0.828530, T: 44826438, Avg. loss: 0.322162\n",
      "Total training time: 40.31 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 269.88, NNZs: 589993, Bias: -0.828707, T: 45303315, Avg. loss: 0.322103\n",
      "Total training time: 40.72 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 269.88, NNZs: 589993, Bias: -0.825233, T: 45780192, Avg. loss: 0.322045\n",
      "Total training time: 41.12 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 269.88, NNZs: 589993, Bias: -0.828761, T: 46257069, Avg. loss: 0.321989\n",
      "Total training time: 41.54 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 269.87, NNZs: 589993, Bias: -0.818018, T: 46733946, Avg. loss: 0.321933\n",
      "Total training time: 41.95 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 269.86, NNZs: 589993, Bias: -0.833996, T: 47210823, Avg. loss: 0.321878\n",
      "Total training time: 42.35 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 269.86, NNZs: 589993, Bias: -0.826858, T: 47687700, Avg. loss: 0.321825\n",
      "Total training time: 42.78 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 269.85, NNZs: 589993, Bias: -0.819649, T: 48164577, Avg. loss: 0.321772\n",
      "Total training time: 43.19 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 269.84, NNZs: 589993, Bias: -0.826719, T: 48641454, Avg. loss: 0.321720\n",
      "Total training time: 43.60 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 269.84, NNZs: 589993, Bias: -0.837746, T: 49118331, Avg. loss: 0.321670\n",
      "Total training time: 44.05 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 269.83, NNZs: 589993, Bias: -0.835977, T: 49595208, Avg. loss: 0.321620\n",
      "Total training time: 44.47 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 269.83, NNZs: 589993, Bias: -0.822233, T: 50072085, Avg. loss: 0.321571\n",
      "Total training time: 44.88 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 269.82, NNZs: 589993, Bias: -0.828139, T: 50548962, Avg. loss: 0.321523\n",
      "Total training time: 45.29 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 269.82, NNZs: 589993, Bias: -0.826222, T: 51025839, Avg. loss: 0.321476\n",
      "Total training time: 45.70 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 269.81, NNZs: 589993, Bias: -0.827077, T: 51502716, Avg. loss: 0.321429\n",
      "Total training time: 46.11 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 269.81, NNZs: 589993, Bias: -0.820764, T: 51979593, Avg. loss: 0.321384\n",
      "Total training time: 46.52 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 269.80, NNZs: 589993, Bias: -0.832266, T: 52456470, Avg. loss: 0.321339\n",
      "Total training time: 46.93 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 269.80, NNZs: 589993, Bias: -0.827352, T: 52933347, Avg. loss: 0.321295\n",
      "Total training time: 47.44 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 269.79, NNZs: 589993, Bias: -0.828238, T: 53410224, Avg. loss: 0.321252\n",
      "Total training time: 47.87 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 269.78, NNZs: 589993, Bias: -0.825472, T: 53887101, Avg. loss: 0.321209\n",
      "Total training time: 48.32 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 269.78, NNZs: 589993, Bias: -0.825433, T: 54363978, Avg. loss: 0.321167\n",
      "Total training time: 48.73 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 269.78, NNZs: 589993, Bias: -0.826042, T: 54840855, Avg. loss: 0.321126\n",
      "Total training time: 49.13 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 269.77, NNZs: 589993, Bias: -0.829919, T: 55317732, Avg. loss: 0.321085\n",
      "Total training time: 49.55 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 269.77, NNZs: 589993, Bias: -0.828740, T: 55794609, Avg. loss: 0.321045\n",
      "Total training time: 49.96 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 269.76, NNZs: 589993, Bias: -0.822649, T: 56271486, Avg. loss: 0.321006\n",
      "Total training time: 50.37 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 269.76, NNZs: 589993, Bias: -0.827779, T: 56748363, Avg. loss: 0.320967\n",
      "Total training time: 50.79 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 269.76, NNZs: 589993, Bias: -0.819826, T: 57225240, Avg. loss: 0.320929\n",
      "Total training time: 51.20 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 269.75, NNZs: 589993, Bias: -0.828935, T: 57702117, Avg. loss: 0.320891\n",
      "Total training time: 51.61 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 269.75, NNZs: 589993, Bias: -0.818273, T: 58178994, Avg. loss: 0.320854\n",
      "Total training time: 52.02 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 269.74, NNZs: 589993, Bias: -0.828623, T: 58655871, Avg. loss: 0.320818\n",
      "Total training time: 52.47 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 269.74, NNZs: 589993, Bias: -0.824114, T: 59132748, Avg. loss: 0.320782\n",
      "Total training time: 52.93 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 269.74, NNZs: 589993, Bias: -0.824611, T: 59609625, Avg. loss: 0.320747\n",
      "Total training time: 53.36 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 269.73, NNZs: 589993, Bias: -0.832875, T: 60086502, Avg. loss: 0.320712\n",
      "Total training time: 53.78 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 269.73, NNZs: 589993, Bias: -0.824385, T: 60563379, Avg. loss: 0.320678\n",
      "Total training time: 54.18 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 269.72, NNZs: 589993, Bias: -0.820736, T: 61040256, Avg. loss: 0.320644\n",
      "Total training time: 54.60 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 269.72, NNZs: 589993, Bias: -0.826667, T: 61517133, Avg. loss: 0.320611\n",
      "Total training time: 55.06 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 269.71, NNZs: 589993, Bias: -0.830004, T: 61994010, Avg. loss: 0.320578\n",
      "Total training time: 55.52 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 269.71, NNZs: 589993, Bias: -0.824200, T: 62470887, Avg. loss: 0.320546\n",
      "Total training time: 55.98 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 269.71, NNZs: 589993, Bias: -0.819514, T: 62947764, Avg. loss: 0.320514\n",
      "Total training time: 56.39 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 269.71, NNZs: 589993, Bias: -0.827534, T: 63424641, Avg. loss: 0.320482\n",
      "Total training time: 56.80 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 269.70, NNZs: 589993, Bias: -0.832188, T: 63901518, Avg. loss: 0.320451\n",
      "Total training time: 57.27 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 269.70, NNZs: 589993, Bias: -0.834114, T: 64378395, Avg. loss: 0.320421\n",
      "Total training time: 57.73 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 269.70, NNZs: 589993, Bias: -0.821435, T: 64855272, Avg. loss: 0.320391\n",
      "Total training time: 58.16 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 269.69, NNZs: 589993, Bias: -0.825652, T: 65332149, Avg. loss: 0.320361\n",
      "Total training time: 58.57 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 269.69, NNZs: 589993, Bias: -0.825149, T: 65809026, Avg. loss: 0.320332\n",
      "Total training time: 58.99 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 269.69, NNZs: 589993, Bias: -0.817108, T: 66285903, Avg. loss: 0.320303\n",
      "Total training time: 59.44 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 269.69, NNZs: 589993, Bias: -0.830199, T: 66762780, Avg. loss: 0.320274\n",
      "Total training time: 59.87 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 269.68, NNZs: 589993, Bias: -0.824864, T: 67239657, Avg. loss: 0.320246\n",
      "Total training time: 60.32 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 269.68, NNZs: 589993, Bias: -0.828762, T: 67716534, Avg. loss: 0.320218\n",
      "Total training time: 60.79 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 269.68, NNZs: 589993, Bias: -0.830417, T: 68193411, Avg. loss: 0.320191\n",
      "Total training time: 61.21 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 269.67, NNZs: 589993, Bias: -0.821691, T: 68670288, Avg. loss: 0.320164\n",
      "Total training time: 61.62 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 269.67, NNZs: 589993, Bias: -0.817857, T: 69147165, Avg. loss: 0.320137\n",
      "Total training time: 62.04 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 269.67, NNZs: 589993, Bias: -0.824348, T: 69624042, Avg. loss: 0.320111\n",
      "Total training time: 62.45 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 269.67, NNZs: 589993, Bias: -0.824816, T: 70100919, Avg. loss: 0.320085\n",
      "Total training time: 62.87 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 269.66, NNZs: 589993, Bias: -0.821113, T: 70577796, Avg. loss: 0.320059\n",
      "Total training time: 63.30 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 269.66, NNZs: 589993, Bias: -0.833215, T: 71054673, Avg. loss: 0.320033\n",
      "Total training time: 63.71 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 269.66, NNZs: 589993, Bias: -0.823210, T: 71531550, Avg. loss: 0.320008\n",
      "Total training time: 64.12 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 269.66, NNZs: 589993, Bias: -0.823823, T: 72008427, Avg. loss: 0.319983\n",
      "Total training time: 64.53 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 269.65, NNZs: 589993, Bias: -0.824022, T: 72485304, Avg. loss: 0.319959\n",
      "Total training time: 64.94 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 269.65, NNZs: 589993, Bias: -0.821605, T: 72962181, Avg. loss: 0.319935\n",
      "Total training time: 65.36 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 269.64, NNZs: 589993, Bias: -0.829415, T: 73439058, Avg. loss: 0.319911\n",
      "Total training time: 65.77 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 269.64, NNZs: 589993, Bias: -0.828377, T: 73915935, Avg. loss: 0.319887\n",
      "Total training time: 66.18 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 269.64, NNZs: 589993, Bias: -0.822320, T: 74392812, Avg. loss: 0.319864\n",
      "Total training time: 66.61 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 269.64, NNZs: 589993, Bias: -0.835368, T: 74869689, Avg. loss: 0.319841\n",
      "Total training time: 67.07 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 269.63, NNZs: 589993, Bias: -0.827410, T: 75346566, Avg. loss: 0.319818\n",
      "Total training time: 67.48 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 269.63, NNZs: 589993, Bias: -0.828499, T: 75823443, Avg. loss: 0.319796\n",
      "Total training time: 67.89 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 269.63, NNZs: 589993, Bias: -0.826743, T: 76300320, Avg. loss: 0.319774\n",
      "Total training time: 68.31 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 269.63, NNZs: 589993, Bias: -0.832122, T: 76777197, Avg. loss: 0.319752\n",
      "Total training time: 68.78 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 269.63, NNZs: 589993, Bias: -0.825382, T: 77254074, Avg. loss: 0.319730\n",
      "Total training time: 69.19 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 269.62, NNZs: 589993, Bias: -0.828387, T: 77730951, Avg. loss: 0.319709\n",
      "Total training time: 69.65 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 269.62, NNZs: 589993, Bias: -0.827100, T: 78207828, Avg. loss: 0.319687\n",
      "Total training time: 70.12 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 269.62, NNZs: 589993, Bias: -0.826864, T: 78684705, Avg. loss: 0.319666\n",
      "Total training time: 70.61 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 269.62, NNZs: 589993, Bias: -0.824768, T: 79161582, Avg. loss: 0.319646\n",
      "Total training time: 71.02 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 269.62, NNZs: 589993, Bias: -0.824945, T: 79638459, Avg. loss: 0.319625\n",
      "Total training time: 71.46 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 269.61, NNZs: 589993, Bias: -0.826916, T: 80115336, Avg. loss: 0.319605\n",
      "Total training time: 71.86 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 269.61, NNZs: 589993, Bias: -0.829945, T: 80592213, Avg. loss: 0.319585\n",
      "Total training time: 72.33 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 269.61, NNZs: 589993, Bias: -0.823487, T: 81069090, Avg. loss: 0.319565\n",
      "Total training time: 72.73 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 269.61, NNZs: 589993, Bias: -0.825734, T: 81545967, Avg. loss: 0.319545\n",
      "Total training time: 73.15 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 269.60, NNZs: 589993, Bias: -0.825284, T: 82022844, Avg. loss: 0.319526\n",
      "Total training time: 73.62 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 269.60, NNZs: 589993, Bias: -0.820467, T: 82499721, Avg. loss: 0.319507\n",
      "Total training time: 74.03 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 269.60, NNZs: 589993, Bias: -0.822199, T: 82976598, Avg. loss: 0.319488\n",
      "Total training time: 74.45 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 269.60, NNZs: 589993, Bias: -0.824040, T: 83453475, Avg. loss: 0.319469\n",
      "Total training time: 74.86 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 269.60, NNZs: 589993, Bias: -0.821993, T: 83930352, Avg. loss: 0.319450\n",
      "Total training time: 75.30 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 269.59, NNZs: 589993, Bias: -0.823730, T: 84407229, Avg. loss: 0.319432\n",
      "Total training time: 75.73 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 269.59, NNZs: 589993, Bias: -0.826904, T: 84884106, Avg. loss: 0.319414\n",
      "Total training time: 76.14 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 269.59, NNZs: 589993, Bias: -0.824815, T: 85360983, Avg. loss: 0.319396\n",
      "Total training time: 76.55 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 269.59, NNZs: 589993, Bias: -0.820993, T: 85837860, Avg. loss: 0.319378\n",
      "Total training time: 77.00 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 269.59, NNZs: 589993, Bias: -0.824337, T: 86314737, Avg. loss: 0.319360\n",
      "Total training time: 77.48 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 269.59, NNZs: 589993, Bias: -0.819861, T: 86791614, Avg. loss: 0.319343\n",
      "Total training time: 77.94 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 269.58, NNZs: 589993, Bias: -0.829566, T: 87268491, Avg. loss: 0.319326\n",
      "Total training time: 78.42 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 269.58, NNZs: 589993, Bias: -0.827271, T: 87745368, Avg. loss: 0.319309\n",
      "Total training time: 78.92 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 269.58, NNZs: 589993, Bias: -0.825570, T: 88222245, Avg. loss: 0.319292\n",
      "Total training time: 79.41 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 269.58, NNZs: 589993, Bias: -0.824335, T: 88699122, Avg. loss: 0.319275\n",
      "Total training time: 79.88 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 269.57, NNZs: 589993, Bias: -0.831717, T: 89175999, Avg. loss: 0.319258\n",
      "Total training time: 80.36 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 269.57, NNZs: 589993, Bias: -0.824883, T: 89652876, Avg. loss: 0.319242\n",
      "Total training time: 80.84 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 269.57, NNZs: 589993, Bias: -0.824252, T: 90129753, Avg. loss: 0.319226\n",
      "Total training time: 81.31 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 269.57, NNZs: 589993, Bias: -0.828236, T: 90606630, Avg. loss: 0.319210\n",
      "Total training time: 81.73 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 269.57, NNZs: 589993, Bias: -0.824487, T: 91083507, Avg. loss: 0.319194\n",
      "Total training time: 82.13 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 269.57, NNZs: 589993, Bias: -0.824158, T: 91560384, Avg. loss: 0.319178\n",
      "Total training time: 82.54 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 269.56, NNZs: 589993, Bias: -0.823143, T: 92037261, Avg. loss: 0.319162\n",
      "Total training time: 82.94 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 269.56, NNZs: 589993, Bias: -0.832011, T: 92514138, Avg. loss: 0.319147\n",
      "Total training time: 83.35 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 269.56, NNZs: 589993, Bias: -0.824623, T: 92991015, Avg. loss: 0.319131\n",
      "Total training time: 83.78 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 269.56, NNZs: 589993, Bias: -0.829870, T: 93467892, Avg. loss: 0.319116\n",
      "Total training time: 84.19 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 269.56, NNZs: 589993, Bias: -0.828167, T: 93944769, Avg. loss: 0.319101\n",
      "Total training time: 84.60 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 269.56, NNZs: 589993, Bias: -0.827850, T: 94421646, Avg. loss: 0.319086\n",
      "Total training time: 85.01 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 269.55, NNZs: 589993, Bias: -0.825644, T: 94898523, Avg. loss: 0.319072\n",
      "Total training time: 85.41 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 269.55, NNZs: 589993, Bias: -0.832873, T: 95375400, Avg. loss: 0.319057\n",
      "Total training time: 85.88 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 269.55, NNZs: 589993, Bias: -0.829251, T: 95852277, Avg. loss: 0.319043\n",
      "Total training time: 86.34 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 269.55, NNZs: 589993, Bias: -0.828777, T: 96329154, Avg. loss: 0.319028\n",
      "Total training time: 86.77 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 269.55, NNZs: 589993, Bias: -0.827606, T: 96806031, Avg. loss: 0.319014\n",
      "Total training time: 87.18 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 269.55, NNZs: 589993, Bias: -0.828109, T: 97282908, Avg. loss: 0.319000\n",
      "Total training time: 87.59 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 269.55, NNZs: 589993, Bias: -0.828891, T: 97759785, Avg. loss: 0.318986\n",
      "Total training time: 88.00 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 269.54, NNZs: 589993, Bias: -0.824618, T: 98236662, Avg. loss: 0.318972\n",
      "Total training time: 88.41 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 269.54, NNZs: 589993, Bias: -0.830533, T: 98713539, Avg. loss: 0.318958\n",
      "Total training time: 88.85 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 269.54, NNZs: 589993, Bias: -0.827929, T: 99190416, Avg. loss: 0.318945\n",
      "Total training time: 89.28 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 269.54, NNZs: 589993, Bias: -0.826489, T: 99667293, Avg. loss: 0.318931\n",
      "Total training time: 89.69 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 269.54, NNZs: 589993, Bias: -0.828896, T: 100144170, Avg. loss: 0.318918\n",
      "Total training time: 90.10 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 269.54, NNZs: 589993, Bias: -0.821987, T: 100621047, Avg. loss: 0.318905\n",
      "Total training time: 90.51 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 269.54, NNZs: 589993, Bias: -0.826448, T: 101097924, Avg. loss: 0.318892\n",
      "Total training time: 90.92 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 269.54, NNZs: 589993, Bias: -0.823308, T: 101574801, Avg. loss: 0.318879\n",
      "Total training time: 91.33 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 269.53, NNZs: 589993, Bias: -0.830780, T: 102051678, Avg. loss: 0.318866\n",
      "Total training time: 91.74 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 269.53, NNZs: 589993, Bias: -0.830368, T: 102528555, Avg. loss: 0.318853\n",
      "Total training time: 92.15 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 269.53, NNZs: 589993, Bias: -0.829222, T: 103005432, Avg. loss: 0.318841\n",
      "Total training time: 92.59 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 269.53, NNZs: 589993, Bias: -0.821612, T: 103482309, Avg. loss: 0.318828\n",
      "Total training time: 93.02 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 269.53, NNZs: 589993, Bias: -0.823595, T: 103959186, Avg. loss: 0.318816\n",
      "Total training time: 93.46 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 269.53, NNZs: 589993, Bias: -0.828302, T: 104436063, Avg. loss: 0.318803\n",
      "Total training time: 93.96 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 269.53, NNZs: 589993, Bias: -0.824858, T: 104912940, Avg. loss: 0.318791\n",
      "Total training time: 94.46 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 269.52, NNZs: 589993, Bias: -0.827173, T: 105389817, Avg. loss: 0.318779\n",
      "Total training time: 94.98 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 269.52, NNZs: 589993, Bias: -0.831948, T: 105866694, Avg. loss: 0.318767\n",
      "Total training time: 95.50 seconds.\n",
      "-- Epoch 223\n",
      "Norm: 269.52, NNZs: 589993, Bias: -0.825069, T: 106343571, Avg. loss: 0.318755\n",
      "Total training time: 95.98 seconds.\n",
      "-- Epoch 224\n",
      "Norm: 269.52, NNZs: 589993, Bias: -0.827151, T: 106820448, Avg. loss: 0.318743\n",
      "Total training time: 96.39 seconds.\n",
      "-- Epoch 225\n",
      "Norm: 269.52, NNZs: 589993, Bias: -0.828773, T: 107297325, Avg. loss: 0.318731\n",
      "Total training time: 96.81 seconds.\n",
      "-- Epoch 226\n",
      "Norm: 269.52, NNZs: 589993, Bias: -0.829115, T: 107774202, Avg. loss: 0.318720\n",
      "Total training time: 97.27 seconds.\n",
      "-- Epoch 227\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.830263, T: 108251079, Avg. loss: 0.318708\n",
      "Total training time: 97.74 seconds.\n",
      "-- Epoch 228\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.824440, T: 108727956, Avg. loss: 0.318697\n",
      "Total training time: 98.21 seconds.\n",
      "-- Epoch 229\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.823691, T: 109204833, Avg. loss: 0.318685\n",
      "Total training time: 98.67 seconds.\n",
      "-- Epoch 230\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.826554, T: 109681710, Avg. loss: 0.318674\n",
      "Total training time: 99.10 seconds.\n",
      "-- Epoch 231\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.824847, T: 110158587, Avg. loss: 0.318663\n",
      "Total training time: 99.52 seconds.\n",
      "-- Epoch 232\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.820360, T: 110635464, Avg. loss: 0.318652\n",
      "Total training time: 99.94 seconds.\n",
      "-- Epoch 233\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.824870, T: 111112341, Avg. loss: 0.318641\n",
      "Total training time: 100.36 seconds.\n",
      "-- Epoch 234\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.824280, T: 111589218, Avg. loss: 0.318630\n",
      "Total training time: 100.78 seconds.\n",
      "-- Epoch 235\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.822903, T: 112066095, Avg. loss: 0.318619\n",
      "Total training time: 101.20 seconds.\n",
      "-- Epoch 236\n",
      "Norm: 269.51, NNZs: 589993, Bias: -0.822883, T: 112542972, Avg. loss: 0.318609\n",
      "Total training time: 101.61 seconds.\n",
      "-- Epoch 237\n",
      "Norm: 269.50, NNZs: 589993, Bias: -0.824245, T: 113019849, Avg. loss: 0.318598\n",
      "Total training time: 102.04 seconds.\n",
      "-- Epoch 238\n",
      "Norm: 269.50, NNZs: 589993, Bias: -0.822459, T: 113496726, Avg. loss: 0.318588\n",
      "Total training time: 102.46 seconds.\n",
      "-- Epoch 239\n",
      "Norm: 269.50, NNZs: 589993, Bias: -0.821800, T: 113973603, Avg. loss: 0.318577\n",
      "Total training time: 102.87 seconds.\n",
      "-- Epoch 240\n",
      "Norm: 269.50, NNZs: 589993, Bias: -0.824385, T: 114450480, Avg. loss: 0.318567\n",
      "Total training time: 103.29 seconds.\n",
      "-- Epoch 241\n",
      "Norm: 269.50, NNZs: 589993, Bias: -0.827270, T: 114927357, Avg. loss: 0.318556\n",
      "Total training time: 103.71 seconds.\n",
      "-- Epoch 242\n",
      "Norm: 269.50, NNZs: 589993, Bias: -0.830878, T: 115404234, Avg. loss: 0.318546\n",
      "Total training time: 104.12 seconds.\n",
      "-- Epoch 243\n",
      "Norm: 269.50, NNZs: 589993, Bias: -0.828037, T: 115881111, Avg. loss: 0.318536\n",
      "Total training time: 104.59 seconds.\n",
      "-- Epoch 244\n",
      "Norm: 269.50, NNZs: 589993, Bias: -0.829045, T: 116357988, Avg. loss: 0.318526\n",
      "Total training time: 105.05 seconds.\n",
      "-- Epoch 245\n",
      "Norm: 269.50, NNZs: 589993, Bias: -0.828355, T: 116834865, Avg. loss: 0.318516\n",
      "Total training time: 105.50 seconds.\n",
      "-- Epoch 246\n",
      "Norm: 269.49, NNZs: 589993, Bias: -0.830182, T: 117311742, Avg. loss: 0.318506\n",
      "Total training time: 105.91 seconds.\n",
      "-- Epoch 247\n",
      "Norm: 269.49, NNZs: 589993, Bias: -0.826044, T: 117788619, Avg. loss: 0.318496\n",
      "Total training time: 106.32 seconds.\n",
      "-- Epoch 248\n",
      "Norm: 269.49, NNZs: 589993, Bias: -0.828874, T: 118265496, Avg. loss: 0.318487\n",
      "Total training time: 106.74 seconds.\n",
      "-- Epoch 249\n",
      "Norm: 269.49, NNZs: 589993, Bias: -0.825325, T: 118742373, Avg. loss: 0.318477\n",
      "Total training time: 107.15 seconds.\n",
      "-- Epoch 250\n",
      "Norm: 269.49, NNZs: 589993, Bias: -0.824106, T: 119219250, Avg. loss: 0.318467\n",
      "Total training time: 107.60 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 365.55, NNZs: 589993, Bias: -0.060301, T: 476877, Avg. loss: 0.959625\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 315.47, NNZs: 589993, Bias: -0.213572, T: 953754, Avg. loss: 0.748372\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 302.27, NNZs: 589993, Bias: -0.023078, T: 1430631, Avg. loss: 0.667738\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 296.16, NNZs: 589993, Bias: -0.117702, T: 1907508, Avg. loss: 0.624429\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 292.72, NNZs: 589993, Bias: -0.024860, T: 2384385, Avg. loss: 0.597160\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 290.54, NNZs: 589993, Bias: -0.133047, T: 2861262, Avg. loss: 0.578311\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 288.99, NNZs: 589993, Bias: -0.146026, T: 3338139, Avg. loss: 0.564443\n",
      "Total training time: 2.93 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 287.74, NNZs: 589993, Bias: -0.055492, T: 3815016, Avg. loss: 0.553805\n",
      "Total training time: 3.35 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 286.89, NNZs: 589993, Bias: -0.103784, T: 4291893, Avg. loss: 0.545355\n",
      "Total training time: 3.75 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 286.12, NNZs: 589993, Bias: -0.067421, T: 4768770, Avg. loss: 0.538461\n",
      "Total training time: 4.16 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 285.58, NNZs: 589993, Bias: -0.092940, T: 5245647, Avg. loss: 0.532723\n",
      "Total training time: 4.58 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 285.09, NNZs: 589993, Bias: -0.061930, T: 5722524, Avg. loss: 0.527873\n",
      "Total training time: 4.99 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 284.68, NNZs: 589993, Bias: -0.126058, T: 6199401, Avg. loss: 0.523721\n",
      "Total training time: 5.40 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 284.34, NNZs: 589993, Bias: -0.061863, T: 6676278, Avg. loss: 0.520117\n",
      "Total training time: 5.89 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 284.02, NNZs: 589993, Bias: -0.046038, T: 7153155, Avg. loss: 0.516960\n",
      "Total training time: 6.35 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 283.80, NNZs: 589993, Bias: -0.085544, T: 7630032, Avg. loss: 0.514169\n",
      "Total training time: 6.86 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 283.53, NNZs: 589993, Bias: -0.042054, T: 8106909, Avg. loss: 0.511683\n",
      "Total training time: 7.30 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 283.32, NNZs: 589993, Bias: -0.054213, T: 8583786, Avg. loss: 0.509453\n",
      "Total training time: 7.71 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 283.15, NNZs: 589993, Bias: -0.052453, T: 9060663, Avg. loss: 0.507441\n",
      "Total training time: 8.12 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 282.98, NNZs: 589993, Bias: -0.083073, T: 9537540, Avg. loss: 0.505615\n",
      "Total training time: 8.53 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 282.81, NNZs: 589993, Bias: -0.054779, T: 10014417, Avg. loss: 0.503951\n",
      "Total training time: 8.94 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 282.68, NNZs: 589993, Bias: -0.050199, T: 10491294, Avg. loss: 0.502426\n",
      "Total training time: 9.35 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 282.57, NNZs: 589993, Bias: -0.061601, T: 10968171, Avg. loss: 0.501025\n",
      "Total training time: 9.76 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 282.47, NNZs: 589993, Bias: -0.048591, T: 11445048, Avg. loss: 0.499730\n",
      "Total training time: 10.17 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 282.34, NNZs: 589993, Bias: -0.075374, T: 11921925, Avg. loss: 0.498533\n",
      "Total training time: 10.58 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 282.24, NNZs: 589993, Bias: -0.075132, T: 12398802, Avg. loss: 0.497419\n",
      "Total training time: 10.99 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 282.14, NNZs: 589993, Bias: -0.093411, T: 12875679, Avg. loss: 0.496385\n",
      "Total training time: 11.39 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 282.07, NNZs: 589993, Bias: -0.067883, T: 13352556, Avg. loss: 0.495419\n",
      "Total training time: 11.80 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 281.99, NNZs: 589993, Bias: -0.105508, T: 13829433, Avg. loss: 0.494515\n",
      "Total training time: 12.22 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 281.91, NNZs: 589993, Bias: -0.083108, T: 14306310, Avg. loss: 0.493667\n",
      "Total training time: 12.62 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 281.84, NNZs: 589993, Bias: -0.060074, T: 14783187, Avg. loss: 0.492868\n",
      "Total training time: 13.03 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 281.77, NNZs: 589993, Bias: -0.079552, T: 15260064, Avg. loss: 0.492116\n",
      "Total training time: 13.43 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 281.70, NNZs: 589993, Bias: -0.074323, T: 15736941, Avg. loss: 0.491408\n",
      "Total training time: 13.84 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 281.64, NNZs: 589993, Bias: -0.083138, T: 16213818, Avg. loss: 0.490737\n",
      "Total training time: 14.25 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 281.59, NNZs: 589993, Bias: -0.089116, T: 16690695, Avg. loss: 0.490102\n",
      "Total training time: 14.66 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 281.53, NNZs: 589993, Bias: -0.076581, T: 17167572, Avg. loss: 0.489500\n",
      "Total training time: 15.07 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 281.49, NNZs: 589993, Bias: -0.084262, T: 17644449, Avg. loss: 0.488929\n",
      "Total training time: 15.48 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 281.44, NNZs: 589993, Bias: -0.083942, T: 18121326, Avg. loss: 0.488385\n",
      "Total training time: 15.95 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 281.39, NNZs: 589993, Bias: -0.077829, T: 18598203, Avg. loss: 0.487868\n",
      "Total training time: 16.45 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 281.34, NNZs: 589993, Bias: -0.075007, T: 19075080, Avg. loss: 0.487374\n",
      "Total training time: 16.95 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 281.31, NNZs: 589993, Bias: -0.066331, T: 19551957, Avg. loss: 0.486903\n",
      "Total training time: 17.47 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 281.26, NNZs: 589993, Bias: -0.067890, T: 20028834, Avg. loss: 0.486453\n",
      "Total training time: 17.93 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 281.22, NNZs: 589993, Bias: -0.067616, T: 20505711, Avg. loss: 0.486022\n",
      "Total training time: 18.38 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 281.20, NNZs: 589993, Bias: -0.080023, T: 20982588, Avg. loss: 0.485609\n",
      "Total training time: 18.80 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 281.16, NNZs: 589993, Bias: -0.076877, T: 21459465, Avg. loss: 0.485213\n",
      "Total training time: 19.35 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 281.14, NNZs: 589993, Bias: -0.093015, T: 21936342, Avg. loss: 0.484833\n",
      "Total training time: 19.81 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 281.10, NNZs: 589993, Bias: -0.084218, T: 22413219, Avg. loss: 0.484469\n",
      "Total training time: 20.24 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 281.07, NNZs: 589993, Bias: -0.090288, T: 22890096, Avg. loss: 0.484119\n",
      "Total training time: 20.67 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 281.03, NNZs: 589993, Bias: -0.058043, T: 23366973, Avg. loss: 0.483782\n",
      "Total training time: 21.13 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 281.01, NNZs: 589993, Bias: -0.079984, T: 23843850, Avg. loss: 0.483457\n",
      "Total training time: 21.71 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 280.98, NNZs: 589993, Bias: -0.079156, T: 24320727, Avg. loss: 0.483144\n",
      "Total training time: 22.19 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 280.95, NNZs: 589993, Bias: -0.060823, T: 24797604, Avg. loss: 0.482843\n",
      "Total training time: 22.63 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 280.93, NNZs: 589993, Bias: -0.075609, T: 25274481, Avg. loss: 0.482552\n",
      "Total training time: 23.05 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 280.91, NNZs: 589993, Bias: -0.056794, T: 25751358, Avg. loss: 0.482271\n",
      "Total training time: 23.46 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 280.89, NNZs: 589993, Bias: -0.074207, T: 26228235, Avg. loss: 0.482000\n",
      "Total training time: 23.88 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 280.86, NNZs: 589993, Bias: -0.096334, T: 26705112, Avg. loss: 0.481738\n",
      "Total training time: 24.36 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 280.84, NNZs: 589993, Bias: -0.086599, T: 27181989, Avg. loss: 0.481484\n",
      "Total training time: 24.83 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 280.82, NNZs: 589993, Bias: -0.070919, T: 27658866, Avg. loss: 0.481239\n",
      "Total training time: 25.29 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 280.80, NNZs: 589993, Bias: -0.073457, T: 28135743, Avg. loss: 0.481001\n",
      "Total training time: 25.74 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 280.79, NNZs: 589993, Bias: -0.092560, T: 28612620, Avg. loss: 0.480771\n",
      "Total training time: 26.16 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 280.77, NNZs: 589993, Bias: -0.065333, T: 29089497, Avg. loss: 0.480547\n",
      "Total training time: 26.57 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 280.75, NNZs: 589993, Bias: -0.071696, T: 29566374, Avg. loss: 0.480331\n",
      "Total training time: 27.05 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 280.72, NNZs: 589993, Bias: -0.084167, T: 30043251, Avg. loss: 0.480120\n",
      "Total training time: 27.48 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 280.71, NNZs: 589993, Bias: -0.088159, T: 30520128, Avg. loss: 0.479916\n",
      "Total training time: 27.89 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 280.70, NNZs: 589993, Bias: -0.065858, T: 30997005, Avg. loss: 0.479718\n",
      "Total training time: 28.30 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 280.68, NNZs: 589993, Bias: -0.070439, T: 31473882, Avg. loss: 0.479525\n",
      "Total training time: 28.71 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 280.65, NNZs: 589993, Bias: -0.054278, T: 31950759, Avg. loss: 0.479337\n",
      "Total training time: 29.13 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 280.64, NNZs: 589993, Bias: -0.079883, T: 32427636, Avg. loss: 0.479155\n",
      "Total training time: 29.58 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 280.62, NNZs: 589993, Bias: -0.078502, T: 32904513, Avg. loss: 0.478978\n",
      "Total training time: 30.04 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 280.62, NNZs: 589993, Bias: -0.071177, T: 33381390, Avg. loss: 0.478805\n",
      "Total training time: 30.48 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 280.60, NNZs: 589993, Bias: -0.068548, T: 33858267, Avg. loss: 0.478637\n",
      "Total training time: 30.92 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 280.58, NNZs: 589993, Bias: -0.068034, T: 34335144, Avg. loss: 0.478474\n",
      "Total training time: 31.38 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 280.57, NNZs: 589993, Bias: -0.068884, T: 34812021, Avg. loss: 0.478314\n",
      "Total training time: 31.79 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 280.56, NNZs: 589993, Bias: -0.080564, T: 35288898, Avg. loss: 0.478159\n",
      "Total training time: 32.20 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 280.53, NNZs: 589993, Bias: -0.076509, T: 35765775, Avg. loss: 0.478008\n",
      "Total training time: 32.67 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 280.53, NNZs: 589993, Bias: -0.076859, T: 36242652, Avg. loss: 0.477860\n",
      "Total training time: 33.13 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 280.51, NNZs: 589993, Bias: -0.070727, T: 36719529, Avg. loss: 0.477715\n",
      "Total training time: 33.58 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 280.50, NNZs: 589993, Bias: -0.073518, T: 37196406, Avg. loss: 0.477574\n",
      "Total training time: 33.99 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 280.49, NNZs: 589993, Bias: -0.059540, T: 37673283, Avg. loss: 0.477436\n",
      "Total training time: 34.40 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 280.47, NNZs: 589993, Bias: -0.087066, T: 38150160, Avg. loss: 0.477302\n",
      "Total training time: 34.85 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 280.47, NNZs: 589993, Bias: -0.081155, T: 38627037, Avg. loss: 0.477171\n",
      "Total training time: 35.28 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 280.46, NNZs: 589993, Bias: -0.073979, T: 39103914, Avg. loss: 0.477043\n",
      "Total training time: 35.70 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 280.44, NNZs: 589993, Bias: -0.067882, T: 39580791, Avg. loss: 0.476918\n",
      "Total training time: 36.15 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 280.43, NNZs: 589993, Bias: -0.086608, T: 40057668, Avg. loss: 0.476795\n",
      "Total training time: 36.59 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 280.42, NNZs: 589993, Bias: -0.071013, T: 40534545, Avg. loss: 0.476675\n",
      "Total training time: 37.05 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 280.41, NNZs: 589993, Bias: -0.072867, T: 41011422, Avg. loss: 0.476558\n",
      "Total training time: 37.48 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 280.40, NNZs: 589993, Bias: -0.069120, T: 41488299, Avg. loss: 0.476443\n",
      "Total training time: 37.95 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 280.39, NNZs: 589993, Bias: -0.070649, T: 41965176, Avg. loss: 0.476331\n",
      "Total training time: 38.39 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 280.38, NNZs: 589993, Bias: -0.066832, T: 42442053, Avg. loss: 0.476221\n",
      "Total training time: 38.81 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 280.37, NNZs: 589993, Bias: -0.076394, T: 42918930, Avg. loss: 0.476113\n",
      "Total training time: 39.23 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 280.37, NNZs: 589993, Bias: -0.075038, T: 43395807, Avg. loss: 0.476008\n",
      "Total training time: 39.66 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 280.35, NNZs: 589993, Bias: -0.079960, T: 43872684, Avg. loss: 0.475904\n",
      "Total training time: 40.10 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 280.35, NNZs: 589993, Bias: -0.072498, T: 44349561, Avg. loss: 0.475803\n",
      "Total training time: 40.56 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 280.34, NNZs: 589993, Bias: -0.071795, T: 44826438, Avg. loss: 0.475704\n",
      "Total training time: 40.99 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 280.33, NNZs: 589993, Bias: -0.070829, T: 45303315, Avg. loss: 0.475607\n",
      "Total training time: 41.40 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 280.32, NNZs: 589993, Bias: -0.079415, T: 45780192, Avg. loss: 0.475511\n",
      "Total training time: 41.96 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 280.31, NNZs: 589993, Bias: -0.065931, T: 46257069, Avg. loss: 0.475418\n",
      "Total training time: 42.41 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 280.30, NNZs: 589993, Bias: -0.067427, T: 46733946, Avg. loss: 0.475326\n",
      "Total training time: 42.88 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 280.29, NNZs: 589993, Bias: -0.056547, T: 47210823, Avg. loss: 0.475236\n",
      "Total training time: 43.33 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 280.29, NNZs: 589993, Bias: -0.070063, T: 47687700, Avg. loss: 0.475148\n",
      "Total training time: 43.74 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 280.28, NNZs: 589993, Bias: -0.071509, T: 48164577, Avg. loss: 0.475061\n",
      "Total training time: 44.16 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 280.28, NNZs: 589993, Bias: -0.078836, T: 48641454, Avg. loss: 0.474976\n",
      "Total training time: 44.57 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 280.27, NNZs: 589993, Bias: -0.079729, T: 49118331, Avg. loss: 0.474892\n",
      "Total training time: 44.98 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 280.26, NNZs: 589993, Bias: -0.078697, T: 49595208, Avg. loss: 0.474810\n",
      "Total training time: 45.41 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 280.25, NNZs: 589993, Bias: -0.074852, T: 50072085, Avg. loss: 0.474730\n",
      "Total training time: 45.97 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 280.25, NNZs: 589993, Bias: -0.080771, T: 50548962, Avg. loss: 0.474650\n",
      "Total training time: 46.41 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 280.24, NNZs: 589993, Bias: -0.068624, T: 51025839, Avg. loss: 0.474573\n",
      "Total training time: 46.84 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 280.23, NNZs: 589993, Bias: -0.073513, T: 51502716, Avg. loss: 0.474496\n",
      "Total training time: 47.32 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 280.23, NNZs: 589993, Bias: -0.062761, T: 51979593, Avg. loss: 0.474421\n",
      "Total training time: 47.75 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 280.22, NNZs: 589993, Bias: -0.074832, T: 52456470, Avg. loss: 0.474347\n",
      "Total training time: 48.19 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 280.21, NNZs: 589993, Bias: -0.076981, T: 52933347, Avg. loss: 0.474274\n",
      "Total training time: 48.61 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 280.21, NNZs: 589993, Bias: -0.080210, T: 53410224, Avg. loss: 0.474203\n",
      "Total training time: 49.04 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 280.20, NNZs: 589993, Bias: -0.066784, T: 53887101, Avg. loss: 0.474133\n",
      "Total training time: 49.45 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 280.20, NNZs: 589993, Bias: -0.086695, T: 54363978, Avg. loss: 0.474064\n",
      "Total training time: 49.88 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 280.19, NNZs: 589993, Bias: -0.068567, T: 54840855, Avg. loss: 0.473996\n",
      "Total training time: 50.32 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 280.19, NNZs: 589993, Bias: -0.076997, T: 55317732, Avg. loss: 0.473929\n",
      "Total training time: 50.77 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 280.18, NNZs: 589993, Bias: -0.075698, T: 55794609, Avg. loss: 0.473863\n",
      "Total training time: 51.23 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 280.17, NNZs: 589993, Bias: -0.074916, T: 56271486, Avg. loss: 0.473798\n",
      "Total training time: 51.67 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 280.17, NNZs: 589993, Bias: -0.090681, T: 56748363, Avg. loss: 0.473734\n",
      "Total training time: 52.11 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 280.17, NNZs: 589993, Bias: -0.088051, T: 57225240, Avg. loss: 0.473672\n",
      "Total training time: 52.53 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 280.16, NNZs: 589993, Bias: -0.076878, T: 57702117, Avg. loss: 0.473610\n",
      "Total training time: 53.00 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 280.15, NNZs: 589993, Bias: -0.064010, T: 58178994, Avg. loss: 0.473549\n",
      "Total training time: 53.45 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 280.15, NNZs: 589993, Bias: -0.062898, T: 58655871, Avg. loss: 0.473489\n",
      "Total training time: 53.90 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 280.14, NNZs: 589993, Bias: -0.073545, T: 59132748, Avg. loss: 0.473430\n",
      "Total training time: 54.41 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 280.14, NNZs: 589993, Bias: -0.081499, T: 59609625, Avg. loss: 0.473372\n",
      "Total training time: 54.86 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 280.13, NNZs: 589993, Bias: -0.072741, T: 60086502, Avg. loss: 0.473315\n",
      "Total training time: 55.29 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 280.13, NNZs: 589993, Bias: -0.067297, T: 60563379, Avg. loss: 0.473258\n",
      "Total training time: 55.77 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 280.12, NNZs: 589993, Bias: -0.076089, T: 61040256, Avg. loss: 0.473203\n",
      "Total training time: 56.21 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 280.12, NNZs: 589993, Bias: -0.070239, T: 61517133, Avg. loss: 0.473148\n",
      "Total training time: 56.66 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 280.11, NNZs: 589993, Bias: -0.074953, T: 61994010, Avg. loss: 0.473094\n",
      "Total training time: 57.12 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 280.11, NNZs: 589993, Bias: -0.075340, T: 62470887, Avg. loss: 0.473041\n",
      "Total training time: 57.54 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 280.10, NNZs: 589993, Bias: -0.070561, T: 62947764, Avg. loss: 0.472989\n",
      "Total training time: 58.01 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 280.10, NNZs: 589993, Bias: -0.088375, T: 63424641, Avg. loss: 0.472937\n",
      "Total training time: 58.46 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 280.10, NNZs: 589993, Bias: -0.075658, T: 63901518, Avg. loss: 0.472886\n",
      "Total training time: 58.89 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 280.09, NNZs: 589993, Bias: -0.066416, T: 64378395, Avg. loss: 0.472836\n",
      "Total training time: 59.33 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 280.09, NNZs: 589993, Bias: -0.073423, T: 64855272, Avg. loss: 0.472786\n",
      "Total training time: 59.76 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 280.08, NNZs: 589993, Bias: -0.069869, T: 65332149, Avg. loss: 0.472737\n",
      "Total training time: 60.20 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 280.08, NNZs: 589993, Bias: -0.071632, T: 65809026, Avg. loss: 0.472689\n",
      "Total training time: 60.66 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 280.08, NNZs: 589993, Bias: -0.069518, T: 66285903, Avg. loss: 0.472641\n",
      "Total training time: 61.09 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 280.07, NNZs: 589993, Bias: -0.067302, T: 66762780, Avg. loss: 0.472594\n",
      "Total training time: 61.50 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 280.07, NNZs: 589993, Bias: -0.083995, T: 67239657, Avg. loss: 0.472548\n",
      "Total training time: 61.92 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 280.06, NNZs: 589993, Bias: -0.075697, T: 67716534, Avg. loss: 0.472502\n",
      "Total training time: 62.42 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 280.06, NNZs: 589993, Bias: -0.060762, T: 68193411, Avg. loss: 0.472457\n",
      "Total training time: 62.87 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 280.05, NNZs: 589993, Bias: -0.071950, T: 68670288, Avg. loss: 0.472412\n",
      "Total training time: 63.30 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 280.05, NNZs: 589993, Bias: -0.078070, T: 69147165, Avg. loss: 0.472368\n",
      "Total training time: 63.71 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 280.04, NNZs: 589993, Bias: -0.066204, T: 69624042, Avg. loss: 0.472325\n",
      "Total training time: 64.12 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 280.04, NNZs: 589993, Bias: -0.071936, T: 70100919, Avg. loss: 0.472282\n",
      "Total training time: 64.53 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 280.04, NNZs: 589993, Bias: -0.068462, T: 70577796, Avg. loss: 0.472240\n",
      "Total training time: 64.98 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 280.04, NNZs: 589993, Bias: -0.073136, T: 71054673, Avg. loss: 0.472198\n",
      "Total training time: 65.44 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 280.03, NNZs: 589993, Bias: -0.070660, T: 71531550, Avg. loss: 0.472157\n",
      "Total training time: 65.90 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 280.03, NNZs: 589993, Bias: -0.080079, T: 72008427, Avg. loss: 0.472116\n",
      "Total training time: 66.47 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 280.02, NNZs: 589993, Bias: -0.077677, T: 72485304, Avg. loss: 0.472076\n",
      "Total training time: 66.94 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 280.02, NNZs: 589993, Bias: -0.071613, T: 72962181, Avg. loss: 0.472036\n",
      "Total training time: 67.44 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 280.02, NNZs: 589993, Bias: -0.073572, T: 73439058, Avg. loss: 0.471997\n",
      "Total training time: 67.90 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 280.01, NNZs: 589993, Bias: -0.077011, T: 73915935, Avg. loss: 0.471958\n",
      "Total training time: 68.40 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 280.01, NNZs: 589993, Bias: -0.073597, T: 74392812, Avg. loss: 0.471920\n",
      "Total training time: 68.86 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 280.01, NNZs: 589993, Bias: -0.074218, T: 74869689, Avg. loss: 0.471882\n",
      "Total training time: 69.36 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 280.01, NNZs: 589993, Bias: -0.069399, T: 75346566, Avg. loss: 0.471844\n",
      "Total training time: 69.84 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 280.00, NNZs: 589993, Bias: -0.075214, T: 75823443, Avg. loss: 0.471807\n",
      "Total training time: 70.32 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 280.00, NNZs: 589993, Bias: -0.076550, T: 76300320, Avg. loss: 0.471771\n",
      "Total training time: 70.79 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 280.00, NNZs: 589993, Bias: -0.074022, T: 76777197, Avg. loss: 0.471734\n",
      "Total training time: 71.29 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 280.00, NNZs: 589993, Bias: -0.070542, T: 77254074, Avg. loss: 0.471699\n",
      "Total training time: 71.72 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 279.99, NNZs: 589993, Bias: -0.073007, T: 77730951, Avg. loss: 0.471664\n",
      "Total training time: 72.14 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 279.99, NNZs: 589993, Bias: -0.076189, T: 78207828, Avg. loss: 0.471629\n",
      "Total training time: 72.56 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 279.99, NNZs: 589993, Bias: -0.075647, T: 78684705, Avg. loss: 0.471594\n",
      "Total training time: 72.97 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 279.98, NNZs: 589993, Bias: -0.074991, T: 79161582, Avg. loss: 0.471560\n",
      "Total training time: 73.40 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 279.98, NNZs: 589993, Bias: -0.073893, T: 79638459, Avg. loss: 0.471526\n",
      "Total training time: 73.86 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 279.98, NNZs: 589993, Bias: -0.067416, T: 80115336, Avg. loss: 0.471493\n",
      "Total training time: 74.27 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 279.97, NNZs: 589993, Bias: -0.083350, T: 80592213, Avg. loss: 0.471460\n",
      "Total training time: 74.70 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 279.97, NNZs: 589993, Bias: -0.076704, T: 81069090, Avg. loss: 0.471427\n",
      "Total training time: 75.13 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 279.97, NNZs: 589993, Bias: -0.079222, T: 81545967, Avg. loss: 0.471395\n",
      "Total training time: 75.55 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 279.96, NNZs: 589993, Bias: -0.071656, T: 82022844, Avg. loss: 0.471363\n",
      "Total training time: 75.97 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 279.96, NNZs: 589993, Bias: -0.076395, T: 82499721, Avg. loss: 0.471332\n",
      "Total training time: 76.40 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 279.96, NNZs: 589993, Bias: -0.073622, T: 82976598, Avg. loss: 0.471300\n",
      "Total training time: 76.82 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 279.96, NNZs: 589993, Bias: -0.071827, T: 83453475, Avg. loss: 0.471269\n",
      "Total training time: 77.24 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 279.95, NNZs: 589993, Bias: -0.069826, T: 83930352, Avg. loss: 0.471239\n",
      "Total training time: 77.66 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 279.95, NNZs: 589993, Bias: -0.074025, T: 84407229, Avg. loss: 0.471209\n",
      "Total training time: 78.08 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 279.95, NNZs: 589993, Bias: -0.076989, T: 84884106, Avg. loss: 0.471179\n",
      "Total training time: 78.50 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 279.94, NNZs: 589993, Bias: -0.078889, T: 85360983, Avg. loss: 0.471149\n",
      "Total training time: 78.95 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 279.94, NNZs: 589993, Bias: -0.076894, T: 85837860, Avg. loss: 0.471120\n",
      "Total training time: 79.37 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 279.94, NNZs: 589993, Bias: -0.078867, T: 86314737, Avg. loss: 0.471091\n",
      "Total training time: 79.83 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 279.94, NNZs: 589993, Bias: -0.075394, T: 86791614, Avg. loss: 0.471062\n",
      "Total training time: 80.31 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 279.94, NNZs: 589993, Bias: -0.077876, T: 87268491, Avg. loss: 0.471034\n",
      "Total training time: 80.78 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 279.93, NNZs: 589993, Bias: -0.072796, T: 87745368, Avg. loss: 0.471005\n",
      "Total training time: 81.23 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 279.93, NNZs: 589993, Bias: -0.075023, T: 88222245, Avg. loss: 0.470978\n",
      "Total training time: 81.72 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 279.93, NNZs: 589993, Bias: -0.072128, T: 88699122, Avg. loss: 0.470950\n",
      "Total training time: 82.17 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 279.93, NNZs: 589993, Bias: -0.067535, T: 89175999, Avg. loss: 0.470923\n",
      "Total training time: 82.62 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 279.92, NNZs: 589993, Bias: -0.072938, T: 89652876, Avg. loss: 0.470896\n",
      "Total training time: 83.07 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 279.92, NNZs: 589993, Bias: -0.078144, T: 90129753, Avg. loss: 0.470869\n",
      "Total training time: 83.54 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 279.92, NNZs: 589993, Bias: -0.076089, T: 90606630, Avg. loss: 0.470843\n",
      "Total training time: 84.02 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 279.92, NNZs: 589993, Bias: -0.072938, T: 91083507, Avg. loss: 0.470816\n",
      "Total training time: 84.45 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 279.92, NNZs: 589993, Bias: -0.073344, T: 91560384, Avg. loss: 0.470790\n",
      "Total training time: 84.88 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 279.91, NNZs: 589993, Bias: -0.081957, T: 92037261, Avg. loss: 0.470765\n",
      "Total training time: 85.30 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 279.91, NNZs: 589993, Bias: -0.068082, T: 92514138, Avg. loss: 0.470739\n",
      "Total training time: 85.78 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 279.91, NNZs: 589993, Bias: -0.074305, T: 92991015, Avg. loss: 0.470714\n",
      "Total training time: 86.31 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 279.91, NNZs: 589993, Bias: -0.079047, T: 93467892, Avg. loss: 0.470689\n",
      "Total training time: 86.92 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 279.91, NNZs: 589993, Bias: -0.070198, T: 93944769, Avg. loss: 0.470664\n",
      "Total training time: 87.39 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 279.90, NNZs: 589993, Bias: -0.078725, T: 94421646, Avg. loss: 0.470640\n",
      "Total training time: 87.88 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 279.90, NNZs: 589993, Bias: -0.074564, T: 94898523, Avg. loss: 0.470616\n",
      "Total training time: 88.34 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 279.90, NNZs: 589993, Bias: -0.079238, T: 95375400, Avg. loss: 0.470592\n",
      "Total training time: 88.78 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 279.90, NNZs: 589993, Bias: -0.075200, T: 95852277, Avg. loss: 0.470568\n",
      "Total training time: 89.22 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 279.89, NNZs: 589993, Bias: -0.079845, T: 96329154, Avg. loss: 0.470544\n",
      "Total training time: 89.68 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 279.89, NNZs: 589993, Bias: -0.078447, T: 96806031, Avg. loss: 0.470521\n",
      "Total training time: 90.09 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 279.89, NNZs: 589993, Bias: -0.074245, T: 97282908, Avg. loss: 0.470498\n",
      "Total training time: 90.53 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 279.89, NNZs: 589993, Bias: -0.076542, T: 97759785, Avg. loss: 0.470475\n",
      "Total training time: 90.99 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 279.89, NNZs: 589993, Bias: -0.078123, T: 98236662, Avg. loss: 0.470452\n",
      "Total training time: 91.48 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 279.89, NNZs: 589993, Bias: -0.072969, T: 98713539, Avg. loss: 0.470430\n",
      "Total training time: 91.92 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 279.88, NNZs: 589993, Bias: -0.073596, T: 99190416, Avg. loss: 0.470407\n",
      "Total training time: 92.37 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 279.88, NNZs: 589993, Bias: -0.070447, T: 99667293, Avg. loss: 0.470385\n",
      "Total training time: 92.81 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 279.88, NNZs: 589993, Bias: -0.074988, T: 100144170, Avg. loss: 0.470363\n",
      "Total training time: 93.25 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 279.88, NNZs: 589993, Bias: -0.077206, T: 100621047, Avg. loss: 0.470341\n",
      "Total training time: 93.68 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 279.87, NNZs: 589993, Bias: -0.074995, T: 101097924, Avg. loss: 0.470320\n",
      "Total training time: 94.13 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 279.87, NNZs: 589993, Bias: -0.071499, T: 101574801, Avg. loss: 0.470299\n",
      "Total training time: 94.56 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 279.87, NNZs: 589993, Bias: -0.070948, T: 102051678, Avg. loss: 0.470277\n",
      "Total training time: 95.00 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 279.87, NNZs: 589993, Bias: -0.072559, T: 102528555, Avg. loss: 0.470256\n",
      "Total training time: 95.43 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 279.87, NNZs: 589993, Bias: -0.076697, T: 103005432, Avg. loss: 0.470236\n",
      "Total training time: 95.87 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 279.87, NNZs: 589993, Bias: -0.075088, T: 103482309, Avg. loss: 0.470215\n",
      "Total training time: 96.34 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 279.86, NNZs: 589993, Bias: -0.070405, T: 103959186, Avg. loss: 0.470195\n",
      "Total training time: 96.81 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 279.86, NNZs: 589993, Bias: -0.074466, T: 104436063, Avg. loss: 0.470174\n",
      "Total training time: 97.26 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 279.86, NNZs: 589993, Bias: -0.070212, T: 104912940, Avg. loss: 0.470154\n",
      "Total training time: 97.71 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 279.86, NNZs: 589993, Bias: -0.069540, T: 105389817, Avg. loss: 0.470134\n",
      "Total training time: 98.16 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 279.86, NNZs: 589993, Bias: -0.067633, T: 105866694, Avg. loss: 0.470115\n",
      "Total training time: 98.62 seconds.\n",
      "-- Epoch 223\n",
      "Norm: 279.85, NNZs: 589993, Bias: -0.073033, T: 106343571, Avg. loss: 0.470095\n",
      "Total training time: 99.12 seconds.\n",
      "-- Epoch 224\n",
      "Norm: 279.85, NNZs: 589993, Bias: -0.074417, T: 106820448, Avg. loss: 0.470076\n",
      "Total training time: 99.60 seconds.\n",
      "-- Epoch 225\n",
      "Norm: 279.85, NNZs: 589993, Bias: -0.078006, T: 107297325, Avg. loss: 0.470056\n",
      "Total training time: 100.07 seconds.\n",
      "-- Epoch 226\n",
      "Norm: 279.85, NNZs: 589993, Bias: -0.074076, T: 107774202, Avg. loss: 0.470037\n",
      "Total training time: 100.55 seconds.\n",
      "-- Epoch 227\n",
      "Norm: 279.85, NNZs: 589993, Bias: -0.072268, T: 108251079, Avg. loss: 0.470018\n",
      "Total training time: 101.00 seconds.\n",
      "-- Epoch 228\n",
      "Norm: 279.85, NNZs: 589993, Bias: -0.076512, T: 108727956, Avg. loss: 0.470000\n",
      "Total training time: 101.44 seconds.\n",
      "-- Epoch 229\n",
      "Norm: 279.85, NNZs: 589993, Bias: -0.075641, T: 109204833, Avg. loss: 0.469981\n",
      "Total training time: 101.95 seconds.\n",
      "-- Epoch 230\n",
      "Norm: 279.85, NNZs: 589993, Bias: -0.073975, T: 109681710, Avg. loss: 0.469962\n",
      "Total training time: 102.44 seconds.\n",
      "-- Epoch 231\n",
      "Norm: 279.84, NNZs: 589993, Bias: -0.079040, T: 110158587, Avg. loss: 0.469944\n",
      "Total training time: 102.93 seconds.\n",
      "-- Epoch 232\n",
      "Norm: 279.84, NNZs: 589993, Bias: -0.073249, T: 110635464, Avg. loss: 0.469926\n",
      "Total training time: 103.39 seconds.\n",
      "-- Epoch 233\n",
      "Norm: 279.84, NNZs: 589993, Bias: -0.072271, T: 111112341, Avg. loss: 0.469908\n",
      "Total training time: 103.88 seconds.\n",
      "-- Epoch 234\n",
      "Norm: 279.84, NNZs: 589993, Bias: -0.075646, T: 111589218, Avg. loss: 0.469890\n",
      "Total training time: 104.39 seconds.\n",
      "-- Epoch 235\n",
      "Norm: 279.84, NNZs: 589993, Bias: -0.080627, T: 112066095, Avg. loss: 0.469872\n",
      "Total training time: 104.87 seconds.\n",
      "-- Epoch 236\n",
      "Norm: 279.84, NNZs: 589993, Bias: -0.079197, T: 112542972, Avg. loss: 0.469855\n",
      "Total training time: 105.36 seconds.\n",
      "-- Epoch 237\n",
      "Norm: 279.83, NNZs: 589993, Bias: -0.075220, T: 113019849, Avg. loss: 0.469837\n",
      "Total training time: 105.84 seconds.\n",
      "-- Epoch 238\n",
      "Norm: 279.83, NNZs: 589993, Bias: -0.069281, T: 113496726, Avg. loss: 0.469820\n",
      "Total training time: 106.28 seconds.\n",
      "-- Epoch 239\n",
      "Norm: 279.83, NNZs: 589993, Bias: -0.071340, T: 113973603, Avg. loss: 0.469803\n",
      "Total training time: 106.71 seconds.\n",
      "-- Epoch 240\n",
      "Norm: 279.83, NNZs: 589993, Bias: -0.073998, T: 114450480, Avg. loss: 0.469786\n",
      "Total training time: 107.14 seconds.\n",
      "-- Epoch 241\n",
      "Norm: 279.83, NNZs: 589993, Bias: -0.079486, T: 114927357, Avg. loss: 0.469769\n",
      "Total training time: 107.57 seconds.\n",
      "-- Epoch 242\n",
      "Norm: 279.83, NNZs: 589993, Bias: -0.075022, T: 115404234, Avg. loss: 0.469752\n",
      "Total training time: 108.00 seconds.\n",
      "-- Epoch 243\n",
      "Norm: 279.83, NNZs: 589993, Bias: -0.075052, T: 115881111, Avg. loss: 0.469735\n",
      "Total training time: 108.43 seconds.\n",
      "-- Epoch 244\n",
      "Norm: 279.82, NNZs: 589993, Bias: -0.071219, T: 116357988, Avg. loss: 0.469719\n",
      "Total training time: 108.89 seconds.\n",
      "-- Epoch 245\n",
      "Norm: 279.82, NNZs: 589993, Bias: -0.073421, T: 116834865, Avg. loss: 0.469702\n",
      "Total training time: 109.30 seconds.\n",
      "-- Epoch 246\n",
      "Norm: 279.82, NNZs: 589993, Bias: -0.072103, T: 117311742, Avg. loss: 0.469686\n",
      "Total training time: 109.75 seconds.\n",
      "-- Epoch 247\n",
      "Norm: 279.82, NNZs: 589993, Bias: -0.075598, T: 117788619, Avg. loss: 0.469670\n",
      "Total training time: 110.17 seconds.\n",
      "-- Epoch 248\n",
      "Norm: 279.82, NNZs: 589993, Bias: -0.074514, T: 118265496, Avg. loss: 0.469654\n",
      "Total training time: 110.59 seconds.\n",
      "-- Epoch 249\n",
      "Norm: 279.82, NNZs: 589993, Bias: -0.073608, T: 118742373, Avg. loss: 0.469638\n",
      "Total training time: 111.01 seconds.\n",
      "-- Epoch 250\n",
      "Norm: 279.82, NNZs: 589993, Bias: -0.075605, T: 119219250, Avg. loss: 0.469622\n",
      "Total training time: 111.42 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 300.51, NNZs: 589993, Bias: -1.799745, T: 476877, Avg. loss: 0.566966\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 266.03, NNZs: 589993, Bias: -1.689908, T: 953754, Avg. loss: 0.452354\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 256.32, NNZs: 589993, Bias: -1.555931, T: 1430631, Avg. loss: 0.408142\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 251.76, NNZs: 589993, Bias: -1.623316, T: 1907508, Avg. loss: 0.384300\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 249.31, NNZs: 589993, Bias: -1.626820, T: 2384385, Avg. loss: 0.369224\n",
      "Total training time: 2.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 247.89, NNZs: 589993, Bias: -1.589651, T: 2861262, Avg. loss: 0.358750\n",
      "Total training time: 2.60 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 246.84, NNZs: 589993, Bias: -1.588471, T: 3338139, Avg. loss: 0.351028\n",
      "Total training time: 3.10 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 245.98, NNZs: 589993, Bias: -1.620221, T: 3815016, Avg. loss: 0.345062\n",
      "Total training time: 3.51 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 245.34, NNZs: 589993, Bias: -1.618840, T: 4291893, Avg. loss: 0.340319\n",
      "Total training time: 3.95 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 244.89, NNZs: 589993, Bias: -1.645245, T: 4768770, Avg. loss: 0.336455\n",
      "Total training time: 4.38 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 244.47, NNZs: 589993, Bias: -1.628901, T: 5245647, Avg. loss: 0.333230\n",
      "Total training time: 4.86 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 244.15, NNZs: 589993, Bias: -1.586601, T: 5722524, Avg. loss: 0.330495\n",
      "Total training time: 5.32 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 243.89, NNZs: 589993, Bias: -1.657207, T: 6199401, Avg. loss: 0.328151\n",
      "Total training time: 5.74 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 243.66, NNZs: 589993, Bias: -1.584857, T: 6676278, Avg. loss: 0.326114\n",
      "Total training time: 6.17 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 243.41, NNZs: 589993, Bias: -1.597705, T: 7153155, Avg. loss: 0.324326\n",
      "Total training time: 6.66 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 243.23, NNZs: 589993, Bias: -1.599201, T: 7630032, Avg. loss: 0.322743\n",
      "Total training time: 7.12 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 243.05, NNZs: 589993, Bias: -1.588090, T: 8106909, Avg. loss: 0.321330\n",
      "Total training time: 7.55 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 242.93, NNZs: 589993, Bias: -1.573307, T: 8583786, Avg. loss: 0.320064\n",
      "Total training time: 8.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 242.78, NNZs: 589993, Bias: -1.590735, T: 9060663, Avg. loss: 0.318921\n",
      "Total training time: 8.47 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 242.67, NNZs: 589993, Bias: -1.597597, T: 9537540, Avg. loss: 0.317883\n",
      "Total training time: 8.93 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 242.55, NNZs: 589993, Bias: -1.639080, T: 10014417, Avg. loss: 0.316936\n",
      "Total training time: 9.40 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 242.45, NNZs: 589993, Bias: -1.591883, T: 10491294, Avg. loss: 0.316067\n",
      "Total training time: 9.87 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 242.36, NNZs: 589993, Bias: -1.588191, T: 10968171, Avg. loss: 0.315269\n",
      "Total training time: 10.32 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 242.30, NNZs: 589993, Bias: -1.609438, T: 11445048, Avg. loss: 0.314533\n",
      "Total training time: 10.79 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 242.20, NNZs: 589993, Bias: -1.608332, T: 11921925, Avg. loss: 0.313848\n",
      "Total training time: 11.26 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 242.11, NNZs: 589993, Bias: -1.608127, T: 12398802, Avg. loss: 0.313213\n",
      "Total training time: 11.68 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 242.07, NNZs: 589993, Bias: -1.600459, T: 12875679, Avg. loss: 0.312621\n",
      "Total training time: 12.10 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 241.99, NNZs: 589993, Bias: -1.608467, T: 13352556, Avg. loss: 0.312069\n",
      "Total training time: 12.57 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 241.93, NNZs: 589993, Bias: -1.621338, T: 13829433, Avg. loss: 0.311553\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 241.91, NNZs: 589993, Bias: -1.608216, T: 14306310, Avg. loss: 0.311067\n",
      "Total training time: 13.44 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 241.84, NNZs: 589993, Bias: -1.609813, T: 14783187, Avg. loss: 0.310611\n",
      "Total training time: 13.86 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 241.78, NNZs: 589993, Bias: -1.598592, T: 15260064, Avg. loss: 0.310181\n",
      "Total training time: 14.27 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 241.74, NNZs: 589993, Bias: -1.614280, T: 15736941, Avg. loss: 0.309776\n",
      "Total training time: 14.69 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 241.70, NNZs: 589993, Bias: -1.599098, T: 16213818, Avg. loss: 0.309391\n",
      "Total training time: 15.13 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 241.64, NNZs: 589993, Bias: -1.604171, T: 16690695, Avg. loss: 0.309027\n",
      "Total training time: 15.62 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 241.60, NNZs: 589993, Bias: -1.598276, T: 17167572, Avg. loss: 0.308681\n",
      "Total training time: 16.08 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 241.57, NNZs: 589993, Bias: -1.608842, T: 17644449, Avg. loss: 0.308354\n",
      "Total training time: 16.50 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 241.53, NNZs: 589993, Bias: -1.614420, T: 18121326, Avg. loss: 0.308042\n",
      "Total training time: 16.96 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 241.51, NNZs: 589993, Bias: -1.598588, T: 18598203, Avg. loss: 0.307745\n",
      "Total training time: 17.39 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 241.47, NNZs: 589993, Bias: -1.610640, T: 19075080, Avg. loss: 0.307461\n",
      "Total training time: 17.82 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 241.44, NNZs: 589993, Bias: -1.590145, T: 19551957, Avg. loss: 0.307190\n",
      "Total training time: 18.23 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 241.42, NNZs: 589993, Bias: -1.620475, T: 20028834, Avg. loss: 0.306931\n",
      "Total training time: 18.68 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 241.38, NNZs: 589993, Bias: -1.606789, T: 20505711, Avg. loss: 0.306683\n",
      "Total training time: 19.10 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 241.36, NNZs: 589993, Bias: -1.608439, T: 20982588, Avg. loss: 0.306446\n",
      "Total training time: 19.55 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 241.34, NNZs: 589993, Bias: -1.604055, T: 21459465, Avg. loss: 0.306219\n",
      "Total training time: 20.04 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 241.32, NNZs: 589993, Bias: -1.614123, T: 21936342, Avg. loss: 0.306001\n",
      "Total training time: 20.48 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 241.29, NNZs: 589993, Bias: -1.601591, T: 22413219, Avg. loss: 0.305791\n",
      "Total training time: 20.91 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 241.26, NNZs: 589993, Bias: -1.614955, T: 22890096, Avg. loss: 0.305589\n",
      "Total training time: 21.32 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 241.23, NNZs: 589993, Bias: -1.620744, T: 23366973, Avg. loss: 0.305395\n",
      "Total training time: 21.79 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 241.22, NNZs: 589993, Bias: -1.618399, T: 23843850, Avg. loss: 0.305208\n",
      "Total training time: 22.25 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 241.20, NNZs: 589993, Bias: -1.593723, T: 24320727, Avg. loss: 0.305028\n",
      "Total training time: 22.74 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 241.19, NNZs: 589993, Bias: -1.605327, T: 24797604, Avg. loss: 0.304855\n",
      "Total training time: 23.16 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 241.16, NNZs: 589993, Bias: -1.606882, T: 25274481, Avg. loss: 0.304687\n",
      "Total training time: 23.66 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 241.15, NNZs: 589993, Bias: -1.601873, T: 25751358, Avg. loss: 0.304525\n",
      "Total training time: 24.10 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 241.13, NNZs: 589993, Bias: -1.631578, T: 26228235, Avg. loss: 0.304368\n",
      "Total training time: 24.53 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 241.12, NNZs: 589993, Bias: -1.616851, T: 26705112, Avg. loss: 0.304218\n",
      "Total training time: 24.96 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 241.10, NNZs: 589993, Bias: -1.597600, T: 27181989, Avg. loss: 0.304071\n",
      "Total training time: 25.42 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 241.08, NNZs: 589993, Bias: -1.615839, T: 27658866, Avg. loss: 0.303930\n",
      "Total training time: 25.85 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 241.07, NNZs: 589993, Bias: -1.602812, T: 28135743, Avg. loss: 0.303792\n",
      "Total training time: 26.30 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 241.05, NNZs: 589993, Bias: -1.603121, T: 28612620, Avg. loss: 0.303660\n",
      "Total training time: 26.73 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 241.03, NNZs: 589993, Bias: -1.605807, T: 29089497, Avg. loss: 0.303531\n",
      "Total training time: 27.15 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 241.03, NNZs: 589993, Bias: -1.599129, T: 29566374, Avg. loss: 0.303406\n",
      "Total training time: 27.64 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 241.00, NNZs: 589993, Bias: -1.614017, T: 30043251, Avg. loss: 0.303285\n",
      "Total training time: 28.13 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 241.00, NNZs: 589993, Bias: -1.605587, T: 30520128, Avg. loss: 0.303167\n",
      "Total training time: 28.60 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 240.98, NNZs: 589993, Bias: -1.608814, T: 30997005, Avg. loss: 0.303053\n",
      "Total training time: 29.10 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 240.97, NNZs: 589993, Bias: -1.606074, T: 31473882, Avg. loss: 0.302942\n",
      "Total training time: 29.56 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 240.95, NNZs: 589993, Bias: -1.608275, T: 31950759, Avg. loss: 0.302834\n",
      "Total training time: 30.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 240.95, NNZs: 589993, Bias: -1.615966, T: 32427636, Avg. loss: 0.302729\n",
      "Total training time: 30.47 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 240.93, NNZs: 589993, Bias: -1.612359, T: 32904513, Avg. loss: 0.302627\n",
      "Total training time: 30.94 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 240.92, NNZs: 589993, Bias: -1.609463, T: 33381390, Avg. loss: 0.302527\n",
      "Total training time: 31.36 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 240.91, NNZs: 589993, Bias: -1.620954, T: 33858267, Avg. loss: 0.302430\n",
      "Total training time: 31.81 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 240.90, NNZs: 589993, Bias: -1.608811, T: 34335144, Avg. loss: 0.302335\n",
      "Total training time: 32.22 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 240.89, NNZs: 589993, Bias: -1.604417, T: 34812021, Avg. loss: 0.302243\n",
      "Total training time: 32.64 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 240.88, NNZs: 589993, Bias: -1.599039, T: 35288898, Avg. loss: 0.302153\n",
      "Total training time: 33.06 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 240.87, NNZs: 589993, Bias: -1.609048, T: 35765775, Avg. loss: 0.302066\n",
      "Total training time: 33.50 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 240.86, NNZs: 589993, Bias: -1.618053, T: 36242652, Avg. loss: 0.301981\n",
      "Total training time: 33.95 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 240.86, NNZs: 589993, Bias: -1.602498, T: 36719529, Avg. loss: 0.301897\n",
      "Total training time: 34.42 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 240.85, NNZs: 589993, Bias: -1.606949, T: 37196406, Avg. loss: 0.301816\n",
      "Total training time: 34.87 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 240.83, NNZs: 589993, Bias: -1.604277, T: 37673283, Avg. loss: 0.301737\n",
      "Total training time: 35.32 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 240.82, NNZs: 589993, Bias: -1.609744, T: 38150160, Avg. loss: 0.301659\n",
      "Total training time: 35.80 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 240.81, NNZs: 589993, Bias: -1.614920, T: 38627037, Avg. loss: 0.301583\n",
      "Total training time: 36.31 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 240.81, NNZs: 589993, Bias: -1.606326, T: 39103914, Avg. loss: 0.301509\n",
      "Total training time: 36.80 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 240.80, NNZs: 589993, Bias: -1.613905, T: 39580791, Avg. loss: 0.301437\n",
      "Total training time: 37.28 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 240.79, NNZs: 589993, Bias: -1.611967, T: 40057668, Avg. loss: 0.301366\n",
      "Total training time: 37.73 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 240.79, NNZs: 589993, Bias: -1.608794, T: 40534545, Avg. loss: 0.301297\n",
      "Total training time: 38.17 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 240.78, NNZs: 589993, Bias: -1.609823, T: 41011422, Avg. loss: 0.301229\n",
      "Total training time: 38.66 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 240.77, NNZs: 589993, Bias: -1.597127, T: 41488299, Avg. loss: 0.301162\n",
      "Total training time: 39.15 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 240.76, NNZs: 589993, Bias: -1.611133, T: 41965176, Avg. loss: 0.301097\n",
      "Total training time: 39.58 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 240.76, NNZs: 589993, Bias: -1.599464, T: 42442053, Avg. loss: 0.301034\n",
      "Total training time: 40.07 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 240.75, NNZs: 589993, Bias: -1.604908, T: 42918930, Avg. loss: 0.300972\n",
      "Total training time: 40.51 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 240.74, NNZs: 589993, Bias: -1.613156, T: 43395807, Avg. loss: 0.300911\n",
      "Total training time: 40.94 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 240.74, NNZs: 589993, Bias: -1.606558, T: 43872684, Avg. loss: 0.300851\n",
      "Total training time: 41.37 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 240.73, NNZs: 589993, Bias: -1.605190, T: 44349561, Avg. loss: 0.300792\n",
      "Total training time: 41.79 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 240.72, NNZs: 589993, Bias: -1.599974, T: 44826438, Avg. loss: 0.300735\n",
      "Total training time: 42.23 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 240.71, NNZs: 589993, Bias: -1.613034, T: 45303315, Avg. loss: 0.300679\n",
      "Total training time: 42.67 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 240.71, NNZs: 589993, Bias: -1.599876, T: 45780192, Avg. loss: 0.300623\n",
      "Total training time: 43.12 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 240.70, NNZs: 589993, Bias: -1.604319, T: 46257069, Avg. loss: 0.300569\n",
      "Total training time: 43.57 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 240.70, NNZs: 589993, Bias: -1.616097, T: 46733946, Avg. loss: 0.300516\n",
      "Total training time: 43.99 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 240.69, NNZs: 589993, Bias: -1.610485, T: 47210823, Avg. loss: 0.300464\n",
      "Total training time: 44.45 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 240.69, NNZs: 589993, Bias: -1.608227, T: 47687700, Avg. loss: 0.300413\n",
      "Total training time: 44.88 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 240.68, NNZs: 589993, Bias: -1.599619, T: 48164577, Avg. loss: 0.300363\n",
      "Total training time: 45.33 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 240.68, NNZs: 589993, Bias: -1.604874, T: 48641454, Avg. loss: 0.300314\n",
      "Total training time: 45.77 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 240.67, NNZs: 589993, Bias: -1.618831, T: 49118331, Avg. loss: 0.300265\n",
      "Total training time: 46.21 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 240.67, NNZs: 589993, Bias: -1.605180, T: 49595208, Avg. loss: 0.300218\n",
      "Total training time: 46.65 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 240.66, NNZs: 589993, Bias: -1.608302, T: 50072085, Avg. loss: 0.300171\n",
      "Total training time: 47.09 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 240.65, NNZs: 589993, Bias: -1.611469, T: 50548962, Avg. loss: 0.300125\n",
      "Total training time: 47.51 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 240.65, NNZs: 589993, Bias: -1.605568, T: 51025839, Avg. loss: 0.300080\n",
      "Total training time: 47.95 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 240.64, NNZs: 589993, Bias: -1.616540, T: 51502716, Avg. loss: 0.300036\n",
      "Total training time: 48.39 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 240.64, NNZs: 589993, Bias: -1.611094, T: 51979593, Avg. loss: 0.299992\n",
      "Total training time: 48.83 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 240.64, NNZs: 589993, Bias: -1.611164, T: 52456470, Avg. loss: 0.299949\n",
      "Total training time: 49.28 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 240.63, NNZs: 589993, Bias: -1.606014, T: 52933347, Avg. loss: 0.299907\n",
      "Total training time: 49.72 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 240.62, NNZs: 589993, Bias: -1.609061, T: 53410224, Avg. loss: 0.299866\n",
      "Total training time: 50.19 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 240.62, NNZs: 589993, Bias: -1.611006, T: 53887101, Avg. loss: 0.299825\n",
      "Total training time: 50.65 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 240.62, NNZs: 589993, Bias: -1.613553, T: 54363978, Avg. loss: 0.299785\n",
      "Total training time: 51.09 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 240.61, NNZs: 589993, Bias: -1.622282, T: 54840855, Avg. loss: 0.299745\n",
      "Total training time: 51.51 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 240.61, NNZs: 589993, Bias: -1.619860, T: 55317732, Avg. loss: 0.299707\n",
      "Total training time: 51.94 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 240.61, NNZs: 589993, Bias: -1.610273, T: 55794609, Avg. loss: 0.299669\n",
      "Total training time: 52.37 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 240.61, NNZs: 589993, Bias: -1.603053, T: 56271486, Avg. loss: 0.299631\n",
      "Total training time: 52.82 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 240.60, NNZs: 589993, Bias: -1.611354, T: 56748363, Avg. loss: 0.299594\n",
      "Total training time: 53.26 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 240.59, NNZs: 589993, Bias: -1.610957, T: 57225240, Avg. loss: 0.299558\n",
      "Total training time: 53.69 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 240.59, NNZs: 589993, Bias: -1.604984, T: 57702117, Avg. loss: 0.299522\n",
      "Total training time: 54.12 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 240.58, NNZs: 589993, Bias: -1.609340, T: 58178994, Avg. loss: 0.299487\n",
      "Total training time: 54.56 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 240.58, NNZs: 589993, Bias: -1.613482, T: 58655871, Avg. loss: 0.299452\n",
      "Total training time: 55.00 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 240.57, NNZs: 589993, Bias: -1.611370, T: 59132748, Avg. loss: 0.299418\n",
      "Total training time: 55.45 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 240.57, NNZs: 589993, Bias: -1.610184, T: 59609625, Avg. loss: 0.299384\n",
      "Total training time: 55.90 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 240.57, NNZs: 589993, Bias: -1.613261, T: 60086502, Avg. loss: 0.299351\n",
      "Total training time: 56.34 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 240.57, NNZs: 589993, Bias: -1.602604, T: 60563379, Avg. loss: 0.299318\n",
      "Total training time: 56.78 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 240.56, NNZs: 589993, Bias: -1.598361, T: 61040256, Avg. loss: 0.299286\n",
      "Total training time: 57.22 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 240.56, NNZs: 589993, Bias: -1.608962, T: 61517133, Avg. loss: 0.299254\n",
      "Total training time: 57.68 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 240.55, NNZs: 589993, Bias: -1.612153, T: 61994010, Avg. loss: 0.299223\n",
      "Total training time: 58.15 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 240.55, NNZs: 589993, Bias: -1.600371, T: 62470887, Avg. loss: 0.299192\n",
      "Total training time: 58.62 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 240.55, NNZs: 589993, Bias: -1.608114, T: 62947764, Avg. loss: 0.299161\n",
      "Total training time: 59.11 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 240.54, NNZs: 589993, Bias: -1.610215, T: 63424641, Avg. loss: 0.299132\n",
      "Total training time: 59.58 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 240.54, NNZs: 589993, Bias: -1.618028, T: 63901518, Avg. loss: 0.299102\n",
      "Total training time: 60.02 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 240.54, NNZs: 589993, Bias: -1.610931, T: 64378395, Avg. loss: 0.299073\n",
      "Total training time: 60.48 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 240.53, NNZs: 589993, Bias: -1.608880, T: 64855272, Avg. loss: 0.299044\n",
      "Total training time: 60.93 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 240.53, NNZs: 589993, Bias: -1.607296, T: 65332149, Avg. loss: 0.299016\n",
      "Total training time: 61.41 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 240.53, NNZs: 589993, Bias: -1.609687, T: 65809026, Avg. loss: 0.298988\n",
      "Total training time: 61.86 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 240.52, NNZs: 589993, Bias: -1.611000, T: 66285903, Avg. loss: 0.298960\n",
      "Total training time: 62.30 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 240.52, NNZs: 589993, Bias: -1.605732, T: 66762780, Avg. loss: 0.298933\n",
      "Total training time: 62.76 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 240.52, NNZs: 589993, Bias: -1.614321, T: 67239657, Avg. loss: 0.298906\n",
      "Total training time: 63.21 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 240.51, NNZs: 589993, Bias: -1.607199, T: 67716534, Avg. loss: 0.298879\n",
      "Total training time: 63.67 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 240.51, NNZs: 589993, Bias: -1.610981, T: 68193411, Avg. loss: 0.298853\n",
      "Total training time: 64.13 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 240.51, NNZs: 589993, Bias: -1.609168, T: 68670288, Avg. loss: 0.298827\n",
      "Total training time: 64.59 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 240.51, NNZs: 589993, Bias: -1.605874, T: 69147165, Avg. loss: 0.298802\n",
      "Total training time: 65.04 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 240.50, NNZs: 589993, Bias: -1.612283, T: 69624042, Avg. loss: 0.298777\n",
      "Total training time: 65.47 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 240.50, NNZs: 589993, Bias: -1.606274, T: 70100919, Avg. loss: 0.298752\n",
      "Total training time: 65.96 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 240.50, NNZs: 589993, Bias: -1.606812, T: 70577796, Avg. loss: 0.298727\n",
      "Total training time: 66.46 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 240.50, NNZs: 589993, Bias: -1.609437, T: 71054673, Avg. loss: 0.298703\n",
      "Total training time: 66.94 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 240.49, NNZs: 589993, Bias: -1.611760, T: 71531550, Avg. loss: 0.298679\n",
      "Total training time: 67.43 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 240.49, NNZs: 589993, Bias: -1.604129, T: 72008427, Avg. loss: 0.298655\n",
      "Total training time: 67.90 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 240.49, NNZs: 589993, Bias: -1.611964, T: 72485304, Avg. loss: 0.298632\n",
      "Total training time: 68.38 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 240.49, NNZs: 589993, Bias: -1.611335, T: 72962181, Avg. loss: 0.298609\n",
      "Total training time: 68.85 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 240.48, NNZs: 589993, Bias: -1.615293, T: 73439058, Avg. loss: 0.298586\n",
      "Total training time: 69.33 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 240.48, NNZs: 589993, Bias: -1.606457, T: 73915935, Avg. loss: 0.298564\n",
      "Total training time: 69.82 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 240.48, NNZs: 589993, Bias: -1.609901, T: 74392812, Avg. loss: 0.298541\n",
      "Total training time: 70.30 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 240.47, NNZs: 589993, Bias: -1.608749, T: 74869689, Avg. loss: 0.298519\n",
      "Total training time: 70.78 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 240.47, NNZs: 589993, Bias: -1.608171, T: 75346566, Avg. loss: 0.298498\n",
      "Total training time: 71.27 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 240.47, NNZs: 589993, Bias: -1.608113, T: 75823443, Avg. loss: 0.298476\n",
      "Total training time: 71.73 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 240.47, NNZs: 589993, Bias: -1.611706, T: 76300320, Avg. loss: 0.298455\n",
      "Total training time: 72.19 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 240.47, NNZs: 589993, Bias: -1.607536, T: 76777197, Avg. loss: 0.298434\n",
      "Total training time: 72.63 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 240.46, NNZs: 589993, Bias: -1.608829, T: 77254074, Avg. loss: 0.298413\n",
      "Total training time: 73.07 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 240.46, NNZs: 589993, Bias: -1.615372, T: 77730951, Avg. loss: 0.298393\n",
      "Total training time: 73.51 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 240.46, NNZs: 589993, Bias: -1.612293, T: 78207828, Avg. loss: 0.298373\n",
      "Total training time: 73.98 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 240.46, NNZs: 589993, Bias: -1.610466, T: 78684705, Avg. loss: 0.298353\n",
      "Total training time: 74.41 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 240.45, NNZs: 589993, Bias: -1.607204, T: 79161582, Avg. loss: 0.298333\n",
      "Total training time: 74.88 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 240.45, NNZs: 589993, Bias: -1.610386, T: 79638459, Avg. loss: 0.298313\n",
      "Total training time: 75.36 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 240.45, NNZs: 589993, Bias: -1.612284, T: 80115336, Avg. loss: 0.298294\n",
      "Total training time: 75.86 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 240.45, NNZs: 589993, Bias: -1.608982, T: 80592213, Avg. loss: 0.298275\n",
      "Total training time: 76.31 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 240.45, NNZs: 589993, Bias: -1.611473, T: 81069090, Avg. loss: 0.298256\n",
      "Total training time: 76.77 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 240.44, NNZs: 589993, Bias: -1.609051, T: 81545967, Avg. loss: 0.298237\n",
      "Total training time: 77.23 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 240.44, NNZs: 589993, Bias: -1.610829, T: 82022844, Avg. loss: 0.298218\n",
      "Total training time: 77.67 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 240.44, NNZs: 589993, Bias: -1.608101, T: 82499721, Avg. loss: 0.298200\n",
      "Total training time: 78.16 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 240.44, NNZs: 589993, Bias: -1.610500, T: 82976598, Avg. loss: 0.298182\n",
      "Total training time: 78.66 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 240.43, NNZs: 589993, Bias: -1.610343, T: 83453475, Avg. loss: 0.298164\n",
      "Total training time: 79.13 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 240.44, NNZs: 589993, Bias: -1.607348, T: 83930352, Avg. loss: 0.298146\n",
      "Total training time: 79.60 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 240.43, NNZs: 589993, Bias: -1.608369, T: 84407229, Avg. loss: 0.298129\n",
      "Total training time: 80.10 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 240.43, NNZs: 589993, Bias: -1.605681, T: 84884106, Avg. loss: 0.298111\n",
      "Total training time: 80.58 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 240.43, NNZs: 589993, Bias: -1.606302, T: 85360983, Avg. loss: 0.298094\n",
      "Total training time: 81.09 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 240.42, NNZs: 589993, Bias: -1.611669, T: 85837860, Avg. loss: 0.298077\n",
      "Total training time: 81.56 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 240.42, NNZs: 589993, Bias: -1.607140, T: 86314737, Avg. loss: 0.298060\n",
      "Total training time: 82.02 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 240.42, NNZs: 589993, Bias: -1.610965, T: 86791614, Avg. loss: 0.298044\n",
      "Total training time: 82.47 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 240.42, NNZs: 589993, Bias: -1.612324, T: 87268491, Avg. loss: 0.298027\n",
      "Total training time: 82.92 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 240.42, NNZs: 589993, Bias: -1.610424, T: 87745368, Avg. loss: 0.298011\n",
      "Total training time: 83.36 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 240.42, NNZs: 589993, Bias: -1.612893, T: 88222245, Avg. loss: 0.297995\n",
      "Total training time: 83.80 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 240.41, NNZs: 589993, Bias: -1.607222, T: 88699122, Avg. loss: 0.297979\n",
      "Total training time: 84.25 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 240.41, NNZs: 589993, Bias: -1.609500, T: 89175999, Avg. loss: 0.297963\n",
      "Total training time: 84.69 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 240.41, NNZs: 589993, Bias: -1.609286, T: 89652876, Avg. loss: 0.297947\n",
      "Total training time: 85.18 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 240.41, NNZs: 589993, Bias: -1.604978, T: 90129753, Avg. loss: 0.297932\n",
      "Total training time: 85.64 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 240.41, NNZs: 589993, Bias: -1.609618, T: 90606630, Avg. loss: 0.297916\n",
      "Total training time: 86.08 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 240.41, NNZs: 589993, Bias: -1.609243, T: 91083507, Avg. loss: 0.297901\n",
      "Total training time: 86.55 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 240.41, NNZs: 589993, Bias: -1.611360, T: 91560384, Avg. loss: 0.297886\n",
      "Total training time: 87.04 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 240.40, NNZs: 589993, Bias: -1.607612, T: 92037261, Avg. loss: 0.297871\n",
      "Total training time: 87.51 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 240.40, NNZs: 589993, Bias: -1.612725, T: 92514138, Avg. loss: 0.297856\n",
      "Total training time: 87.96 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 240.40, NNZs: 589993, Bias: -1.613499, T: 92991015, Avg. loss: 0.297841\n",
      "Total training time: 88.42 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 240.40, NNZs: 589993, Bias: -1.607327, T: 93467892, Avg. loss: 0.297827\n",
      "Total training time: 88.87 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 240.40, NNZs: 589993, Bias: -1.606603, T: 93944769, Avg. loss: 0.297813\n",
      "Total training time: 89.32 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 240.39, NNZs: 589993, Bias: -1.614949, T: 94421646, Avg. loss: 0.297798\n",
      "Total training time: 89.78 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 240.39, NNZs: 589993, Bias: -1.608636, T: 94898523, Avg. loss: 0.297784\n",
      "Total training time: 90.22 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 240.39, NNZs: 589993, Bias: -1.608476, T: 95375400, Avg. loss: 0.297770\n",
      "Total training time: 90.68 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 240.39, NNZs: 589993, Bias: -1.607813, T: 95852277, Avg. loss: 0.297757\n",
      "Total training time: 91.15 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 240.39, NNZs: 589993, Bias: -1.607939, T: 96329154, Avg. loss: 0.297743\n",
      "Total training time: 91.59 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 240.39, NNZs: 589993, Bias: -1.607637, T: 96806031, Avg. loss: 0.297729\n",
      "Total training time: 92.06 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 240.39, NNZs: 589993, Bias: -1.606925, T: 97282908, Avg. loss: 0.297716\n",
      "Total training time: 92.50 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 240.38, NNZs: 589993, Bias: -1.601505, T: 97759785, Avg. loss: 0.297702\n",
      "Total training time: 92.96 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 240.38, NNZs: 589993, Bias: -1.605551, T: 98236662, Avg. loss: 0.297689\n",
      "Total training time: 93.42 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 240.38, NNZs: 589993, Bias: -1.601747, T: 98713539, Avg. loss: 0.297676\n",
      "Total training time: 93.86 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 240.38, NNZs: 589993, Bias: -1.606975, T: 99190416, Avg. loss: 0.297663\n",
      "Total training time: 94.31 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 240.38, NNZs: 589993, Bias: -1.610497, T: 99667293, Avg. loss: 0.297650\n",
      "Total training time: 94.75 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 240.38, NNZs: 589993, Bias: -1.609879, T: 100144170, Avg. loss: 0.297637\n",
      "Total training time: 95.20 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 240.37, NNZs: 589993, Bias: -1.606910, T: 100621047, Avg. loss: 0.297625\n",
      "Total training time: 95.67 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 240.37, NNZs: 589993, Bias: -1.607967, T: 101097924, Avg. loss: 0.297612\n",
      "Total training time: 96.12 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 240.37, NNZs: 589993, Bias: -1.612730, T: 101574801, Avg. loss: 0.297600\n",
      "Total training time: 96.58 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 240.37, NNZs: 589993, Bias: -1.605794, T: 102051678, Avg. loss: 0.297588\n",
      "Total training time: 97.02 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 240.37, NNZs: 589993, Bias: -1.612395, T: 102528555, Avg. loss: 0.297575\n",
      "Total training time: 97.46 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 240.37, NNZs: 589993, Bias: -1.611392, T: 103005432, Avg. loss: 0.297563\n",
      "Total training time: 97.90 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 240.37, NNZs: 589993, Bias: -1.609666, T: 103482309, Avg. loss: 0.297551\n",
      "Total training time: 98.35 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 240.37, NNZs: 589993, Bias: -1.608527, T: 103959186, Avg. loss: 0.297540\n",
      "Total training time: 98.79 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 240.36, NNZs: 589993, Bias: -1.613370, T: 104436063, Avg. loss: 0.297528\n",
      "Total training time: 99.24 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 240.36, NNZs: 589993, Bias: -1.608641, T: 104912940, Avg. loss: 0.297516\n",
      "Total training time: 99.70 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 240.36, NNZs: 589993, Bias: -1.609575, T: 105389817, Avg. loss: 0.297505\n",
      "Total training time: 100.15 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 240.36, NNZs: 589993, Bias: -1.610177, T: 105866694, Avg. loss: 0.297493\n",
      "Total training time: 100.61 seconds.\n",
      "-- Epoch 223\n",
      "Norm: 240.36, NNZs: 589993, Bias: -1.610304, T: 106343571, Avg. loss: 0.297482\n",
      "Total training time: 101.05 seconds.\n",
      "-- Epoch 224\n",
      "Norm: 240.36, NNZs: 589993, Bias: -1.610558, T: 106820448, Avg. loss: 0.297470\n",
      "Total training time: 101.49 seconds.\n",
      "-- Epoch 225\n",
      "Norm: 240.36, NNZs: 589993, Bias: -1.616474, T: 107297325, Avg. loss: 0.297459\n",
      "Total training time: 101.93 seconds.\n",
      "-- Epoch 226\n",
      "Norm: 240.36, NNZs: 589993, Bias: -1.610745, T: 107774202, Avg. loss: 0.297448\n",
      "Total training time: 102.37 seconds.\n",
      "-- Epoch 227\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.616057, T: 108251079, Avg. loss: 0.297437\n",
      "Total training time: 102.81 seconds.\n",
      "-- Epoch 228\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.608910, T: 108727956, Avg. loss: 0.297426\n",
      "Total training time: 103.25 seconds.\n",
      "-- Epoch 229\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.609288, T: 109204833, Avg. loss: 0.297415\n",
      "Total training time: 103.74 seconds.\n",
      "-- Epoch 230\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.610360, T: 109681710, Avg. loss: 0.297405\n",
      "Total training time: 104.19 seconds.\n",
      "-- Epoch 231\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.610484, T: 110158587, Avg. loss: 0.297394\n",
      "Total training time: 104.65 seconds.\n",
      "-- Epoch 232\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.604960, T: 110635464, Avg. loss: 0.297383\n",
      "Total training time: 105.10 seconds.\n",
      "-- Epoch 233\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.607687, T: 111112341, Avg. loss: 0.297373\n",
      "Total training time: 105.56 seconds.\n",
      "-- Epoch 234\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.609564, T: 111589218, Avg. loss: 0.297363\n",
      "Total training time: 106.05 seconds.\n",
      "-- Epoch 235\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.607976, T: 112066095, Avg. loss: 0.297352\n",
      "Total training time: 106.51 seconds.\n",
      "-- Epoch 236\n",
      "Norm: 240.35, NNZs: 589993, Bias: -1.609288, T: 112542972, Avg. loss: 0.297342\n",
      "Total training time: 106.95 seconds.\n",
      "-- Epoch 237\n",
      "Norm: 240.34, NNZs: 589993, Bias: -1.607364, T: 113019849, Avg. loss: 0.297332\n",
      "Total training time: 107.41 seconds.\n",
      "-- Epoch 238\n",
      "Norm: 240.34, NNZs: 589993, Bias: -1.610518, T: 113496726, Avg. loss: 0.297322\n",
      "Total training time: 107.86 seconds.\n",
      "-- Epoch 239\n",
      "Norm: 240.34, NNZs: 589993, Bias: -1.607714, T: 113973603, Avg. loss: 0.297312\n",
      "Total training time: 108.31 seconds.\n",
      "-- Epoch 240\n",
      "Norm: 240.34, NNZs: 589993, Bias: -1.608930, T: 114450480, Avg. loss: 0.297302\n",
      "Total training time: 108.78 seconds.\n",
      "-- Epoch 241\n",
      "Norm: 240.34, NNZs: 589993, Bias: -1.611119, T: 114927357, Avg. loss: 0.297292\n",
      "Total training time: 109.22 seconds.\n",
      "-- Epoch 242\n",
      "Norm: 240.34, NNZs: 589993, Bias: -1.609044, T: 115404234, Avg. loss: 0.297282\n",
      "Total training time: 109.66 seconds.\n",
      "-- Epoch 243\n",
      "Norm: 240.34, NNZs: 589993, Bias: -1.608042, T: 115881111, Avg. loss: 0.297272\n",
      "Total training time: 110.13 seconds.\n",
      "-- Epoch 244\n",
      "Norm: 240.34, NNZs: 589993, Bias: -1.608883, T: 116357988, Avg. loss: 0.297263\n",
      "Total training time: 110.61 seconds.\n",
      "-- Epoch 245\n",
      "Norm: 240.33, NNZs: 589993, Bias: -1.611322, T: 116834865, Avg. loss: 0.297253\n",
      "Total training time: 111.07 seconds.\n",
      "-- Epoch 246\n",
      "Norm: 240.33, NNZs: 589993, Bias: -1.611982, T: 117311742, Avg. loss: 0.297244\n",
      "Total training time: 111.54 seconds.\n",
      "-- Epoch 247\n",
      "Norm: 240.33, NNZs: 589993, Bias: -1.613298, T: 117788619, Avg. loss: 0.297234\n",
      "Total training time: 111.99 seconds.\n",
      "-- Epoch 248\n",
      "Norm: 240.33, NNZs: 589993, Bias: -1.611358, T: 118265496, Avg. loss: 0.297225\n",
      "Total training time: 112.43 seconds.\n",
      "-- Epoch 249\n",
      "Norm: 240.33, NNZs: 589993, Bias: -1.609272, T: 118742373, Avg. loss: 0.297216\n",
      "Total training time: 112.88 seconds.\n",
      "-- Epoch 250\n",
      "Norm: 240.33, NNZs: 589993, Bias: -1.609391, T: 119219250, Avg. loss: 0.297207\n",
      "Total training time: 113.32 seconds.\n",
      "done in 332.555000s\n",
      "Percentage of non zeros coef: 100.000000\n",
      "Predicting the outcomes of the testing set\n",
      "done in 0.300000s\n",
      "Classification report on test set for classifier:\n",
      "SGDClassifier(alpha=1e-06, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=250, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=True, warm_start=False)\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.75      0.76     70805\n",
      "          2       0.68      0.82      0.74     96773\n",
      "          3       0.65      0.35      0.46     36798\n",
      "\n",
      "avg / total       0.71      0.71      0.70    204376\n",
      "\n",
      "Confusion matrix:\n",
      "[[52750 16779  1276]\n",
      " [12163 78981  5629]\n",
      " [ 2838 20952 13008]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.5min finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Testbenching a logistic Regression...\")\n",
    "parameters = {\n",
    "    'loss': 'log',\n",
    "    'penalty': 'l2',\n",
    "    'n_iter': 250,\n",
    "    'alpha': 0.000001,\n",
    "    'fit_intercept': True,\n",
    "    'verbose':True,\n",
    "}\n",
    "\n",
    "benchmark(SGDClassifier, parameters, 'SGD')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(681253, 724796)\n"
     ]
    }
   ],
   "source": [
    "print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
